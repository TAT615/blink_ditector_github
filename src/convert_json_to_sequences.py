"""
JSONãƒ‡ãƒ¼ã‚¿ã‚’LSTMå­¦ç¿’ç”¨ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«(.npz)ã«å¤‰æ›ï¼ˆ12æ¬¡å…ƒå®Œå…¨å¯¾å¿œç‰ˆï¼‰

ç‰¹å¾´é‡æ§‹æˆï¼ˆ12æ¬¡å…ƒï¼‰:
    [0] closing_time: é–‰çœ¼æ™‚é–“ [ç§’]
    [1] opening_time: é–‹çœ¼æ™‚é–“ [ç§’]
    [2] blink_coefficient: ç¬ãä¿‚æ•° (opening_time / closing_time)
    [3] interval: å‰å›ã®ç¬ãã‹ã‚‰ã®é–“éš” [ç§’]
    [4] total_duration: ç·æŒç¶šæ™‚é–“ [ç§’]
    [5] upper_radius_max: ä¸Šã¾ã¶ãŸå††ã®æœ€å¤§åŠå¾„ [px]
    [6] lower_radius_max: ä¸‹ã¾ã¶ãŸå††ã®æœ€å¤§åŠå¾„ [px]
    [7] vertical_distance_min: ä¸Šä¸‹å††ã®æœ€å°è·é›¢ [px]
    [8] radius_diff_max: åŠå¾„å·®ã®æœ€å¤§å€¤ [px]
    [9] eye_height_min: ç›®ã®é«˜ã•ã®æœ€å°å€¤ [px]
    [10] eye_width_avg: ç›®ã®å¹…ã®å¹³å‡å€¤ [px]
    [11] ear_min: EARã®æœ€å°å€¤

ä½¿ã„æ–¹:
    python convert_json_to_sequences.py --input-dir data/sessions --output-dir data/sequences
"""

import os
import json
import numpy as np
import argparse
from pathlib import Path


class JSONToSequenceConverter:
    """
    JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’LSTMç”¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ï¼ˆ12æ¬¡å…ƒå®Œå…¨å¯¾å¿œç‰ˆï¼‰
    """
    
    # ç‰¹å¾´é‡åã®å®šç¾©ï¼ˆé †åºé‡è¦ï¼‰
    FEATURE_NAMES = [
        'closing_time',           # [0]
        'opening_time',           # [1]
        'blink_coefficient',      # [2]
        'interval',               # [3]
        'total_duration',         # [4]
        'upper_radius_max',       # [5]
        'lower_radius_max',       # [6]
        'vertical_distance_min',  # [7]
        'radius_diff_max',        # [8]
        'eye_height_min',         # [9]
        'eye_width_avg',          # [10]
        'ear_min'                 # [11]
    ]
    
    def __init__(self, sequence_length=10):
        """
        åˆæœŸåŒ–
        
        Args:
            sequence_length (int): ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ï¼‰
        """
        self.sequence_length = sequence_length
        
        print("=" * 70)
        print("ğŸ“¦ JSONâ†’ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å¤‰æ›ã‚·ã‚¹ãƒ†ãƒ ï¼ˆ12æ¬¡å…ƒå®Œå…¨å¯¾å¿œç‰ˆï¼‰")
        print("=" * 70)
        print(f"ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·: {self.sequence_length}")
        print(f"ç‰¹å¾´é‡æ¬¡å…ƒ: {len(self.FEATURE_NAMES)}æ¬¡å…ƒ")
        print("\nç‰¹å¾´é‡æ§‹æˆ:")
        for i, name in enumerate(self.FEATURE_NAMES):
            print(f"  [{i:2d}] {name}")
        print("=" * 70)
    
    def extract_features_from_blink(self, blink_data):
        """
        ç¬ããƒ‡ãƒ¼ã‚¿ã‹ã‚‰12æ¬¡å…ƒç‰¹å¾´é‡ã‚’æŠ½å‡º
        
        Args:
            blink_data (dict): ç¬ããƒ‡ãƒ¼ã‚¿
            
        Returns:
            list: 12æ¬¡å…ƒç‰¹å¾´é‡ ã¾ãŸã¯ None
        """
        try:
            stats = blink_data['statistics']
            
            # 12æ¬¡å…ƒç‰¹å¾´é‡ã‚’æŠ½å‡º
            features = [
                stats.get('closing_time', 0.0),           # [0]
                stats.get('opening_time', 0.0),           # [1]
                stats.get('blink_coefficient', 0.0),      # [2]
                stats.get('interval', 0.0),               # [3]
                stats.get('total_duration', 0.0),         # [4]
                stats.get('upper_radius_max', 0.0),       # [5]
                stats.get('lower_radius_max', 0.0),       # [6]
                stats.get('vertical_distance_min', 0.0),  # [7]
                stats.get('radius_diff_max', 0.0),        # [8]
                stats.get('eye_height_min', 0.0),         # [9]
                stats.get('eye_width_avg', 0.0),          # [10]
                stats.get('ear_min', 0.0)                 # [11]
            ]
            
            return features
            
        except KeyError as e:
            print(f"      âš ï¸ ã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
            return None
        except Exception as e:
            print(f"      âš ï¸ ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _is_valid_blink(self, blink_data):
        """
        ç¬ããƒ‡ãƒ¼ã‚¿ã®æœ‰åŠ¹æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        
        Args:
            blink_data (dict): ç¬ããƒ‡ãƒ¼ã‚¿
            
        Returns:
            bool: æœ‰åŠ¹ãªå ´åˆTrue
        """
        try:
            stats = blink_data['statistics']
            
            # é–‰çœ¼æ™‚é–“ãƒã‚§ãƒƒã‚¯ (25ms - 1000ms)
            closing_time = stats['closing_time']
            if not (0.025 <= closing_time <= 1.0):
                return False
            
            # é–‹çœ¼æ™‚é–“ãƒã‚§ãƒƒã‚¯ (50ms - 600ms)
            opening_time = stats['opening_time']
            if not (0.05 <= opening_time <= 0.6):
                return False
            
            # ç¬ãä¿‚æ•°ãƒã‚§ãƒƒã‚¯ (0.5 - 8.0)
            blink_coefficient = stats['blink_coefficient']
            if not (0.5 <= blink_coefficient <= 8.0):
                return False
            
            return True
            
        except KeyError:
            return False
        except Exception:
            return False
    
    def convert_session_to_sequences(self, json_file):
        """
        1ã¤ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¤‰æ›
        
        Args:
            json_file (str): JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            tuple: (sequences, labels, session_info) ã¾ãŸã¯ None
        """
        try:
            # JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±
            session_id = data.get('session_id', os.path.basename(json_file).replace('.json', ''))
            label = data['label']  # 0: æ­£å¸¸, 1: çœ æ°—
            
            # æœ‰åŠ¹ãªç¬ãã®ã¿ã‚’æŠ½å‡º
            valid_blinks = []
            skipped_count = 0
            
            for blink in data['blinks']:
                # æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
                if self._is_valid_blink(blink):
                    features = self.extract_features_from_blink(blink)
                    if features is not None:
                        valid_blinks.append(features)
                    else:
                        skipped_count += 1
                else:
                    skipped_count += 1
            
            # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã«æº€ãŸãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if len(valid_blinks) < self.sequence_length:
                print(f"    âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: æœ‰åŠ¹ãªç¬ããŒä¸è¶³ ({len(valid_blinks)}/{self.sequence_length})")
                return None
            
            # ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ä½œæˆ
            sequences = []
            for i in range(len(valid_blinks) - self.sequence_length + 1):
                seq = valid_blinks[i:i + self.sequence_length]
                sequences.append(seq)
            
            # NumPyé…åˆ—ã«å¤‰æ›
            sequences = np.array(sequences, dtype=np.float32)
            labels = np.full(len(sequences), label, dtype=np.int64)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±
            label_name = "normal" if label == 0 else "drowsy"
            session_info = {
                'session_id': session_id,
                'label': label,
                'label_name': label_name,
                'total_blinks': len(data['blinks']),
                'used_blinks': len(valid_blinks),
                'skipped_blinks': skipped_count,
                'sequence_count': len(sequences)
            }
            
            return sequences, labels, session_info
            
        except json.JSONDecodeError as e:
            print(f"    âŒ JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            return None
        except KeyError as e:
            print(f"    âŒ å¿…è¦ãªã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“: {e}")
            return None
        except Exception as e:
            print(f"    âŒ å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def convert_directory(self, input_dir, output_dir):
        """
        ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›
        
        Args:
            input_dir (str): å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆJSONãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
            output_dir (str): å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆNPZãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
            
        Returns:
            bool: æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(output_dir, exist_ok=True)
        
        # JSONãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
        json_files = list(Path(input_dir).glob('*.json'))
        
        if len(json_files) == 0:
            print(f"\nâŒ JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_dir}")
            return False
        
        print(f"\nğŸ“‚ {len(json_files)} å€‹ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­...")
        print("=" * 70)
        
        success_count = 0
        total_sequences = 0
        all_sequences = []
        all_labels = []
        
        for json_file in json_files:
            print(f"\nå‡¦ç†ä¸­: {json_file.name}")
            result = self.convert_session_to_sequences(str(json_file))
            
            if result is not None:
                sequences, labels, session_info = result
                
                # NPZãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                session_id = session_info['session_id']
                output_file = os.path.join(output_dir, f"{session_id}_sequences.npz")
                
                np.savez(
                    output_file,
                    sequences=sequences,
                    labels=labels,
                    session_name=session_id,
                    session_info=session_info
                )
                
                label_name = session_info['label_name']
                seq_count = session_info['sequence_count']
                used_blinks = session_info['used_blinks']
                skipped = session_info['skipped_blinks']
                
                print(f"  âœ“ {session_id}: {seq_count} sequences ({label_name})")
                print(f"      ä½¿ç”¨ç¬ã: {used_blinks}, ã‚¹ã‚­ãƒƒãƒ—: {skipped}")
                
                # å…¨ä½“ã«è¿½åŠ 
                all_sequences.append(sequences)
                all_labels.append(labels)
                
                success_count += 1
                total_sequences += seq_count
        
        print("\n" + "=" * 70)
        print(f"\nâœ… å¤‰æ›å®Œäº†")
        print(f"   æˆåŠŸ: {success_count}/{len(json_files)} ã‚»ãƒƒã‚·ãƒ§ãƒ³")
        print(f"   ç·ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ•°: {total_sequences}")
        print(f"   å‡ºåŠ›å…ˆ: {output_dir}")
        
        # çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
        if len(all_sequences) > 0:
            combined_sequences = np.concatenate(all_sequences, axis=0)
            combined_labels = np.concatenate(all_labels, axis=0)
            
            # çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
            combined_file = os.path.join(os.path.dirname(output_dir), 'combined_sequences.npz')
            np.savez(
                combined_file,
                sequences=combined_sequences,
                labels=combined_labels
            )
            print(f"\nğŸ“¦ çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {combined_file}")
            print(f"   ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å½¢çŠ¶: {combined_sequences.shape}")
            print(f"   ãƒ©ãƒ™ãƒ«å½¢çŠ¶: {combined_labels.shape}")
            
            # ã‚¯ãƒ©ã‚¹åˆ¥çµ±è¨ˆ
            normal_count = np.sum(combined_labels == 0)
            drowsy_count = np.sum(combined_labels == 1)
            print(f"\nğŸ“Š ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ:")
            print(f"   æ­£å¸¸ (0): {normal_count} ({normal_count/len(combined_labels)*100:.1f}%)")
            print(f"   çœ æ°— (1): {drowsy_count} ({drowsy_count/len(combined_labels)*100:.1f}%)")
            
            # ç‰¹å¾´é‡ã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
            print(f"\nğŸ“ˆ ç‰¹å¾´é‡ã®çµ±è¨ˆæƒ…å ±:")
            for i, name in enumerate(self.FEATURE_NAMES):
                values = combined_sequences[:, :, i].flatten()
                print(f"   [{i:2d}] {name:25s}: "
                      f"mean={np.mean(values):.4f}, std={np.std(values):.4f}, "
                      f"min={np.min(values):.4f}, max={np.max(values):.4f}")
        
        return success_count > 0


def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    parser = argparse.ArgumentParser(
        description='JSONãƒ‡ãƒ¼ã‚¿ã‚’LSTMå­¦ç¿’ç”¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ï¼ˆ12æ¬¡å…ƒå®Œå…¨å¯¾å¿œç‰ˆï¼‰',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    parser.add_argument('--input-dir', type=str, default='data/sessions',
                       help='å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆJSONãƒ•ã‚¡ã‚¤ãƒ«ï¼‰')
    parser.add_argument('--output-dir', type=str, default='data/sequences',
                       help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆNPZãƒ•ã‚¡ã‚¤ãƒ«ï¼‰')
    parser.add_argument('--sequence-length', type=int, default=10,
                       help='ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·')
    
    args = parser.parse_args()
    
    # å¤‰æ›å™¨ä½œæˆ
    converter = JSONToSequenceConverter(sequence_length=args.sequence_length)
    
    # å¤‰æ›å®Ÿè¡Œ
    success = converter.convert_directory(args.input_dir, args.output_dir)
    
    if success:
        print("\n" + "=" * 70)
        print("ğŸ‰ å¤‰æ›ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        print("=" * 70)
        print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("  1. å­¦ç¿’ã‚’å®Ÿè¡Œ:")
        print("     python -m src.train_drowsiness_model --data-dir data")
        print("=" * 70)
        return 0
    else:
        print("\nâŒ å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return 1


if __name__ == "__main__":
    import sys
    sys.exit(main())
