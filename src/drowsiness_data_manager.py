"""
çœ æ°—æ¨å®šç”¨ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½åˆ†å‰²å¯¾å¿œç‰ˆï¼‰
Drowsiness Data Manager with Session-based Splitting

åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã€å‰å‡¦ç†ã€åˆ†å‰²ã‚’è¡Œã„ã¾ã™ã€‚
ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã‚’é˜²ããŸã‚ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã§ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã¾ã™ã€‚
"""

import os
import json
import numpy as np
from typing import Dict, List, Tuple, Optional
from sklearn.model_selection import train_test_split
import glob


class DrowsinessDataManager:
    """
    çœ æ°—æ¨å®šãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç®¡ç†ã‚¯ãƒ©ã‚¹ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½åˆ†å‰²å¯¾å¿œï¼‰
    
    æ©Ÿèƒ½:
    - ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    - æ­£è¦åŒ–ãƒ»å‰å‡¦ç†
    - ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã§ã®è¨“ç·´/æ¤œè¨¼/ãƒ†ã‚¹ãƒˆåˆ†å‰²ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰
    - ãƒãƒƒãƒç”Ÿæˆ
    """
    
    def __init__(self, data_dir="drowsiness_training_data"):
        """
        åˆæœŸåŒ–
        
        Args:
            data_dir (str): ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.data_dir = data_dir
        self.sessions_dir = os.path.join(data_dir, 'sessions')
        self.sequences_dir = os.path.join(data_dir, 'sequences')
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã®ãƒ‡ãƒ¼ã‚¿
        self.sessions = []  # [{name, sequences, labels, label}, ...]
        
        # çµ±åˆãƒ‡ãƒ¼ã‚¿
        self.all_sequences = []
        self.all_labels = []
        
        # åˆ†å‰²å¾Œã®ãƒ‡ãƒ¼ã‚¿
        self.train_sequences = None
        self.train_labels = None
        self.val_sequences = None
        self.val_labels = None
        self.test_sequences = None
        self.test_labels = None
        
        # åˆ†å‰²æƒ…å ±
        self.train_sessions = []
        self.val_sessions = []
        self.test_sessions = []
        
        # æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.normalization_params = {
            'mean': None,
            'std': None,
            'is_fitted': False
        }
        
        print("=" * 70)
        print("ğŸ“¦ ãƒ‡ãƒ¼ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½åˆ†å‰²å¯¾å¿œç‰ˆï¼‰")
        print("=" * 70)
        print(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.data_dir}")
    
    def load_all_data(self, verbose=True) -> bool:
        """
        å…¨ã¦ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        
        Args:
            verbose (bool): è©³ç´°è¡¨ç¤º
            
        Returns:
            bool: æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        try:
            # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            sequence_files = glob.glob(os.path.join(self.sequences_dir, "*_sequences.npz"))
            
            if len(sequence_files) == 0:
                print("âš ï¸ ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
            
            self.sessions = []
            
            if verbose:
                print(f"\nğŸ“‚ {len(sequence_files)} å€‹ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            
            for seq_file in sequence_files:
                # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
                data = np.load(seq_file)
                sequences = data['sequences']
                labels = data['labels']
                session_name = str(data['session_name'])
                
                # ãƒ©ãƒ™ãƒ«ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã®ãƒ©ãƒ™ãƒ«ï¼‰
                session_label = int(labels[0])
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ä¿å­˜
                self.sessions.append({
                    'name': session_name,
                    'sequences': sequences,
                    'labels': labels,
                    'label': session_label,
                    'count': len(sequences)
                })
                
                if verbose:
                    label_name = 'normal' if session_label == 0 else 'drowsy'
                    print(f"  âœ“ {session_name}: {len(sequences)} sequences ({label_name})")
            
            # çµ±è¨ˆ
            total_sequences = sum(s['count'] for s in self.sessions)
            normal_sessions = [s for s in self.sessions if s['label'] == 0]
            drowsy_sessions = [s for s in self.sessions if s['label'] == 1]
            normal_sequences = sum(s['count'] for s in normal_sessions)
            drowsy_sequences = sum(s['count'] for s in drowsy_sessions)
            
            if verbose:
                print(f"\nâœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
                print(f"   ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(self.sessions)}")
                print(f"     æ­£å¸¸ã‚»ãƒƒã‚·ãƒ§ãƒ³: {len(normal_sessions)} ({normal_sequences} sequences)")
                print(f"     çœ æ°—ã‚»ãƒƒã‚·ãƒ§ãƒ³: {len(drowsy_sessions)} ({drowsy_sequences} sequences)")
                print(f"   ç·ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ•°: {total_sequences}")
                if len(self.sessions) > 0:
                    print(f"   ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å½¢çŠ¶: {self.sessions[0]['sequences'].shape[1:]}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def split_data_by_session(self, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15,
                               random_state=42, verbose=True):
        """
        ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã§ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰
        
        åŒã˜ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¯å…¨ã¦åŒã˜ã‚»ãƒƒãƒˆï¼ˆè¨“ç·´/æ¤œè¨¼/ãƒ†ã‚¹ãƒˆï¼‰ã«é…ç½®ã•ã‚Œã¾ã™ã€‚
        
        Args:
            train_ratio (float): è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ
            val_ratio (float): æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ
            test_ratio (float): ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ
            random_state (int): ä¹±æ•°ã‚·ãƒ¼ãƒ‰
            verbose (bool): è©³ç´°è¡¨ç¤º
        """
        if len(self.sessions) == 0:
            print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        
        # æ­£å¸¸/çœ æ°—ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åˆ†é›¢
        normal_sessions = [s for s in self.sessions if s['label'] == 0]
        drowsy_sessions = [s for s in self.sessions if s['label'] == 1]
        
        if verbose:
            print(f"\nğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã§ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...")
            print(f"   æ­£å¸¸ã‚»ãƒƒã‚·ãƒ§ãƒ³: {len(normal_sessions)}")
            print(f"   çœ æ°—ã‚»ãƒƒã‚·ãƒ§ãƒ³: {len(drowsy_sessions)}")
        
        # å„ã‚¯ãƒ©ã‚¹ã‚’å€‹åˆ¥ã«åˆ†å‰²ï¼ˆå±¤åŒ–æŠ½å‡ºï¼‰
        def split_sessions(sessions, train_r, val_r, test_r, seed):
            if len(sessions) < 3:
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒå°‘ãªã„å ´åˆã¯å…¨ã¦è¨“ç·´ã«
                return sessions, [], []
            
            # ã¾ãšè¨“ç·´+æ¤œè¨¼ vs ãƒ†ã‚¹ãƒˆã«åˆ†å‰²
            train_val, test = train_test_split(
                sessions, 
                test_size=test_r, 
                random_state=seed
            )
            
            # æ¬¡ã«è¨“ç·´ vs æ¤œè¨¼ã«åˆ†å‰²
            if len(train_val) < 2:
                return train_val, [], test
            
            val_ratio_adjusted = val_r / (train_r + val_r)
            train, val = train_test_split(
                train_val, 
                test_size=val_ratio_adjusted, 
                random_state=seed
            )
            
            return train, val, test
        
        # æ­£å¸¸ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åˆ†å‰²
        normal_train, normal_val, normal_test = split_sessions(
            normal_sessions, train_ratio, val_ratio, test_ratio, random_state
        )
        
        # çœ æ°—ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åˆ†å‰²
        drowsy_train, drowsy_val, drowsy_test = split_sessions(
            drowsy_sessions, train_ratio, val_ratio, test_ratio, random_state
        )
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ä¿å­˜
        self.train_sessions = normal_train + drowsy_train
        self.val_sessions = normal_val + drowsy_val
        self.test_sessions = normal_test + drowsy_test
        
        # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’çµ±åˆ
        def merge_sequences(session_list):
            if len(session_list) == 0:
                return np.array([]), np.array([])
            sequences = np.vstack([s['sequences'] for s in session_list])
            labels = np.concatenate([s['labels'] for s in session_list])
            return sequences, labels
        
        self.train_sequences, self.train_labels = merge_sequences(self.train_sessions)
        self.val_sequences, self.val_labels = merge_sequences(self.val_sessions)
        self.test_sequences, self.test_labels = merge_sequences(self.test_sessions)
        
        if verbose:
            print("\n" + "=" * 70)
            print("ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†")
            print("=" * 70)
            
            # è¨“ç·´ã‚»ãƒƒãƒˆ
            train_normal = sum(1 for s in self.train_sessions if s['label'] == 0)
            train_drowsy = sum(1 for s in self.train_sessions if s['label'] == 1)
            train_normal_seq = sum(s['count'] for s in self.train_sessions if s['label'] == 0)
            train_drowsy_seq = sum(s['count'] for s in self.train_sessions if s['label'] == 1)
            print(f"è¨“ç·´ã‚»ãƒƒãƒˆ:")
            print(f"  ã‚»ãƒƒã‚·ãƒ§ãƒ³: {len(self.train_sessions)} (æ­£å¸¸: {train_normal}, çœ æ°—: {train_drowsy})")
            print(f"  ã‚·ãƒ¼ã‚±ãƒ³ã‚¹: {len(self.train_sequences)} (æ­£å¸¸: {train_normal_seq}, çœ æ°—: {train_drowsy_seq})")
            
            # æ¤œè¨¼ã‚»ãƒƒãƒˆ
            val_normal = sum(1 for s in self.val_sessions if s['label'] == 0)
            val_drowsy = sum(1 for s in self.val_sessions if s['label'] == 1)
            val_normal_seq = sum(s['count'] for s in self.val_sessions if s['label'] == 0)
            val_drowsy_seq = sum(s['count'] for s in self.val_sessions if s['label'] == 1)
            print(f"æ¤œè¨¼ã‚»ãƒƒãƒˆ:")
            print(f"  ã‚»ãƒƒã‚·ãƒ§ãƒ³: {len(self.val_sessions)} (æ­£å¸¸: {val_normal}, çœ æ°—: {val_drowsy})")
            print(f"  ã‚·ãƒ¼ã‚±ãƒ³ã‚¹: {len(self.val_sequences)} (æ­£å¸¸: {val_normal_seq}, çœ æ°—: {val_drowsy_seq})")
            
            # ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ
            test_normal = sum(1 for s in self.test_sessions if s['label'] == 0)
            test_drowsy = sum(1 for s in self.test_sessions if s['label'] == 1)
            test_normal_seq = sum(s['count'] for s in self.test_sessions if s['label'] == 0)
            test_drowsy_seq = sum(s['count'] for s in self.test_sessions if s['label'] == 1)
            print(f"ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ:")
            print(f"  ã‚»ãƒƒã‚·ãƒ§ãƒ³: {len(self.test_sessions)} (æ­£å¸¸: {test_normal}, çœ æ°—: {test_drowsy})")
            print(f"  ã‚·ãƒ¼ã‚±ãƒ³ã‚¹: {len(self.test_sequences)} (æ­£å¸¸: {test_normal_seq}, çœ æ°—: {test_drowsy_seq})")
            
            print("=" * 70)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³åã‚’è¡¨ç¤º
            print("\nğŸ“‹ åˆ†å‰²ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³:")
            print(f"  è¨“ç·´: {[s['name'] for s in self.train_sessions]}")
            print(f"  æ¤œè¨¼: {[s['name'] for s in self.val_sessions]}")
            print(f"  ãƒ†ã‚¹ãƒˆ: {[s['name'] for s in self.test_sessions]}")
    
    def normalize_data(self, method='zscore', verbose=True):
        """
        ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆé‡ã‚’ä½¿ç”¨ï¼‰
        
        Args:
            method (str): æ­£è¦åŒ–æ–¹æ³• ('zscore' or 'minmax')
            verbose (bool): è©³ç´°è¡¨ç¤º
        """
        if self.train_sequences is None or len(self.train_sequences) == 0:
            print("âš ï¸ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        if method == 'zscore':
            # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰çµ±è¨ˆé‡ã‚’è¨ˆç®—
            train_flat = self.train_sequences.reshape(-1, self.train_sequences.shape[-1])
            
            mean = np.mean(train_flat, axis=0)
            std = np.std(train_flat, axis=0)
            
            # ã‚¼ãƒ­é™¤ç®—é˜²æ­¢
            std[std == 0] = 1.0
            
            # æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜
            self.normalization_params = {
                'mean': mean.tolist(),
                'std': std.tolist(),
                'is_fitted': True
            }
            
            # æ­£è¦åŒ–ã‚’é©ç”¨
            self.train_sequences = (self.train_sequences - mean) / std
            
            if len(self.val_sequences) > 0:
                self.val_sequences = (self.val_sequences - mean) / std
            
            if len(self.test_sequences) > 0:
                self.test_sequences = (self.test_sequences - mean) / std
            
            if verbose:
                print(f"\nâœ… Z-scoreæ­£è¦åŒ–å®Œäº†ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆé‡ã‚’ä½¿ç”¨ï¼‰")
                print(f"   å¹³å‡: {mean}")
                print(f"   æ¨™æº–åå·®: {std}")
        
        elif method == 'minmax':
            # Min-Maxæ­£è¦åŒ–
            train_flat = self.train_sequences.reshape(-1, self.train_sequences.shape[-1])
            
            min_val = np.min(train_flat, axis=0)
            max_val = np.max(train_flat, axis=0)
            
            # ã‚¼ãƒ­é™¤ç®—é˜²æ­¢
            range_val = max_val - min_val
            range_val[range_val == 0] = 1.0
            
            self.normalization_params = {
                'min': min_val.tolist(),
                'max': max_val.tolist(),
                'is_fitted': True
            }
            
            self.train_sequences = (self.train_sequences - min_val) / range_val
            
            if len(self.val_sequences) > 0:
                self.val_sequences = (self.val_sequences - min_val) / range_val
            
            if len(self.test_sequences) > 0:
                self.test_sequences = (self.test_sequences - min_val) / range_val
            
            if verbose:
                print(f"\nâœ… Min-Maxæ­£è¦åŒ–å®Œäº†")
    
    def get_train_data(self) -> Tuple[np.ndarray, np.ndarray]:
        """è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        return self.train_sequences, self.train_labels
    
    def get_val_data(self) -> Tuple[np.ndarray, np.ndarray]:
        """æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        return self.val_sequences, self.val_labels
    
    def get_test_data(self) -> Tuple[np.ndarray, np.ndarray]:
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        return self.test_sequences, self.test_labels
    
    def save_normalization_params(self, output_path: str):
        """
        æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        
        Args:
            output_path (str): å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        with open(output_path, 'w') as f:
            json.dump(self.normalization_params, f, indent=2)
        print(f"âœ… æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜: {output_path}")
    
    def export_dataset(self, output_path: str):
        """
        ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’NumPyãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        
        Args:
            output_path (str): å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        np.savez(
            output_path,
            train_sequences=self.train_sequences,
            train_labels=self.train_labels,
            val_sequences=self.val_sequences,
            val_labels=self.val_labels,
            test_sequences=self.test_sequences,
            test_labels=self.test_labels,
            normalization_params=self.normalization_params,
            train_session_names=[s['name'] for s in self.train_sessions],
            val_session_names=[s['name'] for s in self.val_sessions],
            test_session_names=[s['name'] for s in self.test_sessions]
        )
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {output_path}")
    
    def load_dataset(self, input_path: str):
        """
        ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿
        
        Args:
            input_path (str): å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        try:
            data = np.load(input_path, allow_pickle=True)
            
            self.train_sequences = data['train_sequences']
            self.train_labels = data['train_labels']
            self.val_sequences = data['val_sequences']
            self.val_labels = data['val_labels']
            self.test_sequences = data['test_sequences']
            self.test_labels = data['test_labels']
            
            if 'normalization_params' in data:
                self.normalization_params = data['normalization_params'].item()
            
            print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿: {input_path}")
            
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    def print_statistics(self):
        """çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º"""
        print("\n" + "=" * 70)
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆ")
        print("=" * 70)
        
        if self.train_sequences is not None and len(self.train_sequences) > 0:
            print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(self.train_sequences)}")
            print(f"  æ­£å¸¸: {np.sum(self.train_labels == 0)}")
            print(f"  çœ æ°—: {np.sum(self.train_labels == 1)}")
        
        if self.val_sequences is not None and len(self.val_sequences) > 0:
            print(f"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(self.val_sequences)}")
            print(f"  æ­£å¸¸: {np.sum(self.val_labels == 0)}")
            print(f"  çœ æ°—: {np.sum(self.val_labels == 1)}")
        
        if self.test_sequences is not None and len(self.test_sequences) > 0:
            print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(self.test_sequences)}")
            print(f"  æ­£å¸¸: {np.sum(self.test_labels == 0)}")
            print(f"  çœ æ°—: {np.sum(self.test_labels == 1)}")
        
        print("=" * 70)


# ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
if __name__ == "__main__":
    print("=" * 70)
    print("ãƒ‡ãƒ¼ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ãƒ†ã‚¹ãƒˆï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½åˆ†å‰²ï¼‰")
    print("=" * 70)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ä½œæˆ
    manager = DrowsinessDataManager(data_dir="data")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\nãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚’è©¦ã¿ã¾ã™...")
    success = manager.load_all_data(verbose=True)
    
    if success:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã§ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        print("\nã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã§ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã¾ã™...")
        manager.split_data_by_session(
            train_ratio=0.7, 
            val_ratio=0.15, 
            test_ratio=0.15
        )
        
        # æ­£è¦åŒ–
        print("\nãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–ã—ã¾ã™...")
        manager.normalize_data(method='zscore')
        
        # çµ±è¨ˆè¡¨ç¤º
        manager.print_statistics()
        
        print("\nâœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
    else:
        print("\nâš ï¸ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    print("=" * 70)
