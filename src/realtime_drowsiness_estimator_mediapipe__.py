"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¨å®šã‚·ã‚¹ãƒ†ãƒ ï¼ˆMediaPipeç‰ˆ - 12æ¬¡å…ƒç‰¹å¾´é‡å®Œå…¨å¯¾å¿œãƒ»çµæœä¿å­˜æ©Ÿèƒ½ä»˜ãï¼‰
Real-time Drowsiness Estimation System with MediaPipe - Full 12D Features with Result Saving

è¨“ç·´æ¸ˆã¿LSTMãƒ¢ãƒ‡ãƒ«ï¼ˆ12æ¬¡å…ƒï¼‰ã‚’ä½¿ç”¨ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§çœ æ°—ã‚’æ¨å®šã—ã¾ã™ã€‚
EARæ‰‹æ³•ã¨2ã¤ã®å††æ‰‹æ³•ã‚’çµ±åˆã—ãŸå®Œå…¨ç‰ˆã€‚

ç‰¹å¾´é‡æ§‹æˆï¼ˆ12æ¬¡å…ƒï¼‰:
    [0] closing_time: é–‰çœ¼æ™‚é–“
    [1] opening_time: é–‹çœ¼æ™‚é–“
    [2] blink_coefficient: ç¬ãä¿‚æ•° (opening_time / closing_time)
    [3] interval: å‰å›ã®ç¬ãã‹ã‚‰ã®é–“éš”
    [4] total_duration: ç·æŒç¶šæ™‚é–“
    [5] upper_radius_max: ä¸Šã¾ã¶ãŸå††ã®æœ€å¤§åŠå¾„
    [6] lower_radius_max: ä¸‹ã¾ã¶ãŸå††ã®æœ€å¤§åŠå¾„
    [7] vertical_distance_min: ä¸Šä¸‹å††ã®æœ€å°è·é›¢
    [8] radius_diff_max: åŠå¾„å·®ã®æœ€å¤§å€¤
    [9] eye_height_min: ç›®ã®é«˜ã•ã®æœ€å°å€¤
    [10] eye_width_avg: ç›®ã®å¹…ã®å¹³å‡å€¤
    [11] ear_min: EARã®æœ€å°å€¤

ä½¿ã„æ–¹:
    python -m src.realtime_drowsiness_estimator_mediapipe \
        --model-path trained_models/drowsiness_lstm_20251125_004040.pth
"""

import os
import sys
import cv2
import numpy as np
import time
import json
from datetime import datetime
from collections import deque
from typing import Dict, Optional, Tuple, List
import argparse
import mediapipe as mp

# PyTorchã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import torch
    import torch.nn as nn
except ImportError as e:
    print(f"âŒ PyTorchã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    print("   pip install torch ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„")
    sys.exit(1)


class EARCalculator:
    """Eye Aspect Ratioï¼ˆEARï¼‰è¨ˆç®—ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def calculate(eye_landmarks):
        """
        EARã‚’è¨ˆç®—
        
        Args:
            eye_landmarks: ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯6ç‚¹ [(x,y), ...]
            
        Returns:
            float: EARå€¤
        """
        if len(eye_landmarks) != 6:
            return 0.0
        
        # å‚ç›´è·é›¢
        v1 = np.linalg.norm(np.array(eye_landmarks[1]) - np.array(eye_landmarks[5]))
        v2 = np.linalg.norm(np.array(eye_landmarks[2]) - np.array(eye_landmarks[4]))
        
        # æ°´å¹³è·é›¢
        h = np.linalg.norm(np.array(eye_landmarks[0]) - np.array(eye_landmarks[3]))
        
        if h == 0:
            return 0.0
        
        # EARè¨ˆç®—
        ear = (v1 + v2) / (2.0 * h)
        return ear


class TwoCircleFitter:
    """2å††ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚¯ãƒ©ã‚¹ï¼ˆä¸Šã¾ã¶ãŸãƒ»ä¸‹ã¾ã¶ãŸï¼‰"""
    
    @staticmethod
    def fit_circle(points):
        """
        3ç‚¹ã‹ã‚‰å††ã‚’ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
        
        Args:
            points: [(x, y), (x, y), (x, y)]
            
        Returns:
            dict: å††ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ {center_x, center_y, radius} ã¾ãŸã¯ None
        """
        if len(points) != 3:
            return None
        
        try:
            points = np.array(points, dtype=np.float32)
            
            # è¡Œåˆ—Aã¨ãƒ™ã‚¯ãƒˆãƒ«bã‚’æ§‹ç¯‰
            A = np.zeros((3, 3))
            b = np.zeros(3)
            
            for i in range(3):
                x, y = points[i]
                A[i] = [2*x, 2*y, 1]
                b[i] = x*x + y*y
            
            # é€£ç«‹æ–¹ç¨‹å¼ã‚’è§£ã
            params = np.linalg.solve(A, b)
            
            center_x = params[0]
            center_y = params[1]
            radius = np.sqrt(params[2] + center_x**2 + center_y**2)
            
            return {
                'center_x': float(center_x),
                'center_y': float(center_y),
                'radius': float(radius)
            }
            
        except Exception as e:
            return None
    
    @staticmethod
    def fit_eyelids(eye_landmarks):
        """
        ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‹ã‚‰ä¸Šã¾ã¶ãŸå††ã¨ä¸‹ã¾ã¶ãŸå††ã‚’ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
        
        Args:
            eye_landmarks: ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯6ç‚¹
                          [P0(å·¦ç«¯), P1(ä¸Šå·¦), P2(ä¸Šå³), P3(å³ç«¯), P4(ä¸‹å³), P5(ä¸‹å·¦)]
            
        Returns:
            dict: 2å††ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ {
                'upper_circle': {center_x, center_y, radius},
                'lower_circle': {center_x, center_y, radius},
                'vertical_distance': ä¸Šä¸‹ã®å††ã®ä¸­å¿ƒé–“è·é›¢,
                'radius_diff': åŠå¾„ã®å·®,
                'eye_height': ç›®ã®é«˜ã•,
                'eye_width': ç›®ã®å¹…
            } ã¾ãŸã¯ None
        """
        if len(eye_landmarks) < 6:
            return None
        
        try:
            # ä¸Šã¾ã¶ãŸ3ç‚¹: P1(ä¸Šå·¦), P2(ä¸Šå³), P3(å³ç«¯)
            upper_points = [eye_landmarks[1], eye_landmarks[2], eye_landmarks[3]]
            upper_circle = TwoCircleFitter.fit_circle(upper_points)
            
            if upper_circle is None:
                return None
            
            # ä¸‹ã¾ã¶ãŸ3ç‚¹: P0(å·¦ç«¯), P4(ä¸‹å³), P5(ä¸‹å·¦)
            lower_points = [eye_landmarks[0], eye_landmarks[4], eye_landmarks[5]]
            lower_circle = TwoCircleFitter.fit_circle(lower_points)
            
            if lower_circle is None:
                return None
            
            # 2å††ã®ä¸­å¿ƒé–“è·é›¢ï¼ˆå‚ç›´è·é›¢ï¼‰
            vertical_distance = np.sqrt(
                (upper_circle['center_x'] - lower_circle['center_x'])**2 +
                (upper_circle['center_y'] - lower_circle['center_y'])**2
            )
            
            # åŠå¾„ã®å·®
            radius_diff = abs(upper_circle['radius'] - lower_circle['radius'])
            
            # ç›®ã®é«˜ã•ï¼ˆä¸Šä¸‹ã®å‚ç›´è·é›¢ã®å¹³å‡ï¼‰
            eye_height = (
                np.linalg.norm(np.array(eye_landmarks[1]) - np.array(eye_landmarks[5])) +
                np.linalg.norm(np.array(eye_landmarks[2]) - np.array(eye_landmarks[4]))
            ) / 2.0
            
            # ç›®ã®å¹…ï¼ˆæ°´å¹³è·é›¢ï¼‰
            eye_width = np.linalg.norm(np.array(eye_landmarks[0]) - np.array(eye_landmarks[3]))
            
            return {
                'upper_circle': upper_circle,
                'lower_circle': lower_circle,
                'vertical_distance': float(vertical_distance),
                'radius_diff': float(radius_diff),
                'eye_height': float(eye_height),
                'eye_width': float(eye_width)
            }
            
        except Exception as e:
            return None


class DrowsinessLSTM(nn.Module):
    """çœ æ°—æ¨å®šç”¨LSTMãƒ¢ãƒ‡ãƒ«ï¼ˆ12æ¬¡å…ƒç‰¹å¾´é‡å¯¾å¿œï¼‰"""
    
    def __init__(self, input_size=12, hidden_size1=64, hidden_size2=32, 
                 fc_size=32, num_classes=2, dropout_rate=0.3):
        super(DrowsinessLSTM, self).__init__()
        
        # 2å±¤LSTM
        self.lstm1 = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size1,
            batch_first=True,
            dropout=dropout_rate if hidden_size2 > 0 else 0
        )
        
        self.lstm2 = nn.LSTM(
            input_size=hidden_size1,
            hidden_size=hidden_size2,
            batch_first=True
        )
        
        # Dropoutå±¤
        self.dropout1 = nn.Dropout(dropout_rate)
        self.dropout2 = nn.Dropout(dropout_rate)
        self.dropout3 = nn.Dropout(dropout_rate)
        
        # å…¨çµåˆå±¤
        self.fc1 = nn.Linear(hidden_size2, fc_size)
        self.fc2 = nn.Linear(fc_size, num_classes)
        self.relu = nn.ReLU()
    
    def forward(self, x):
        # LSTM1
        lstm1_out, _ = self.lstm1(x)
        lstm1_out = self.dropout1(lstm1_out)
        
        # LSTM2
        lstm2_out, _ = self.lstm2(lstm1_out)
        lstm2_out = self.dropout2(lstm2_out)
        
        # æœ€å¾Œã®æ™‚åˆ»ã®å‡ºåŠ›
        last_output = lstm2_out[:, -1, :]
        
        # å…¨çµåˆå±¤
        fc1_out = self.fc1(last_output)
        fc1_out = self.relu(fc1_out)
        fc1_out = self.dropout3(fc1_out)
        
        output = self.fc2(fc1_out)
        
        return output


class RealtimeDrowsinessDetector:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ï¼ˆ12æ¬¡å…ƒç‰¹å¾´é‡å®Œå…¨å¯¾å¿œãƒ»çµæœä¿å­˜æ©Ÿèƒ½ä»˜ãï¼‰"""
    
    # MediaPipe Face Meshã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    LEFT_EYE_INDICES = [362, 385, 387, 263, 373, 380]
    RIGHT_EYE_INDICES = [33, 160, 158, 133, 153, 144]
    
    # ç¬ãçŠ¶æ…‹
    STATE_OPEN = 0
    STATE_CLOSING = 1
    STATE_CLOSED = 2
    STATE_OPENING = 3
    
    def __init__(self, model_path, sequence_length=10, ear_threshold=0.21,
                 output_dir="drowsiness_results"):
        """
        åˆæœŸåŒ–
        
        Args:
            model_path (str): å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
            sequence_length (int): LSTMã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·
            ear_threshold (float): EARé–¾å€¤
            output_dir (str): çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.sequence_length = sequence_length
        self.ear_threshold = ear_threshold
        self.output_dir = output_dir
        self.model_path = model_path
        
        # çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(output_dir, exist_ok=True)
        
        # MediaPipe Face Mesh
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        
        # ç¬ãæ¤œå‡ºç”¨å¤‰æ•°
        self.blink_state = self.STATE_OPEN
        self.state_start_time = time.time()
        self.t1 = 0  # OPEN â†’ CLOSING
        self.t2 = 0  # CLOSING â†’ CLOSED
        self.t3 = 0  # CLOSED â†’ OPENING
        
        # å‰å›ã®ç¬ãæ™‚åˆ»ï¼ˆé–“éš”è¨ˆç®—ç”¨ï¼‰
        self.last_blink_time = None
        
        # 2å††ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€å°å€¤è¿½è·¡ï¼ˆç¬ãä¸­ï¼‰
        self.current_blink_circles_data = []
        
        # EARå±¥æ­´ï¼ˆç¬ãä¸­ã®EARæœ€å°å€¤ã‚’è¨˜éŒ²ï¼‰
        self.current_blink_ear_history = []
        
        # ç‰¹å¾´é‡ãƒãƒƒãƒ•ã‚¡ï¼ˆ12æ¬¡å…ƒ Ã— sequence_lengthï¼‰
        self.feature_buffer = deque(maxlen=sequence_length)
        
        # LSTMãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        print("ğŸ§  ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        checkpoint = torch.load(model_path, map_location=self.device)
        model_params = checkpoint.get('model_params', {})
        
        self.model = DrowsinessLSTM(
            input_size=model_params.get('input_size', 12),
            hidden_size1=model_params.get('hidden_size1', 64),
            hidden_size2=model_params.get('hidden_size2', 32),
            fc_size=model_params.get('fc_size', 32),
            num_classes=model_params.get('num_classes', 2),
            dropout_rate=model_params.get('dropout_rate', 0.3)
        )
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        print(f"   ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
        print(f"   å…¥åŠ›æ¬¡å…ƒ: {model_params.get('input_size', 12)}")
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {model_path}")
        print(f"ğŸ“ çµæœä¿å­˜å…ˆ: {output_dir}")
        
        # æ¨å®šçµæœ
        self.current_prediction = None
        self.current_probability = None
        
        # çµ±è¨ˆ
        self.total_blinks = 0
        self.drowsy_count = 0
        self.normal_count = 0
        self.frame_count = 0
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†
        self.consecutive_drowsy = 0
        self.consecutive_drowsy_threshold = 3
        self.alert_active = False
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ï¼ˆçµæœä¿å­˜ç”¨ï¼‰
        self.session_start_time = datetime.now()
        self.blink_history = []
        self.prediction_history = []
        self.ear_samples = []
        
        print("=" * 70)
        print("ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ï¼ˆçµæœä¿å­˜æ©Ÿèƒ½ä»˜ãï¼‰")
        print("=" * 70)
        print(f"ğŸ“ ãƒ¢ãƒ‡ãƒ«: {model_path}")
        print(f"ğŸ“Š ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·: {sequence_length}")
        print(f"ğŸ‘ï¸  EARé–¾å€¤: {ear_threshold}")
        print(f"ğŸ”¢ ç‰¹å¾´é‡æ¬¡å…ƒ: 12æ¬¡å…ƒï¼ˆTemporal + Spatialï¼‰")
        print(f"ğŸ’¾ çµæœä¿å­˜å…ˆ: {output_dir}")
        print("=" * 70)
    
    def detect_blink(self, ear, left_eye_landmarks, right_eye_landmarks):
        """
        ç¬ãã‚’æ¤œå‡ºã—ã€å®Œäº†æ™‚ã«12æ¬¡å…ƒç‰¹å¾´é‡ã‚’æŠ½å‡º
        
        Args:
            ear (float): Eye Aspect Ratio
            left_eye_landmarks (list): å·¦ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯6ç‚¹
            right_eye_landmarks (list): å³ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯6ç‚¹
            
        Returns:
            np.array: 12æ¬¡å…ƒç‰¹å¾´é‡ ã¾ãŸã¯ None
        """
        current_time = time.time()
        
        # ç¬ãä¸­ã¯2å††ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨EARã‚’è¨˜éŒ²
        if self.blink_state in [self.STATE_CLOSING, self.STATE_CLOSED, self.STATE_OPENING]:
            # EARå±¥æ­´ã‚’è¨˜éŒ²
            self.current_blink_ear_history.append(ear)
            
            # ä¸¡ç›®ã®2å††ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            left_circles = TwoCircleFitter.fit_eyelids(left_eye_landmarks)
            right_circles = TwoCircleFitter.fit_eyelids(right_eye_landmarks)
            
            # å¹³å‡å€¤ã‚’è¨ˆç®—ã—ã¦è¨˜éŒ²
            if left_circles and right_circles:
                avg_circles = {
                    'upper_radius': (left_circles['upper_circle']['radius'] + 
                                   right_circles['upper_circle']['radius']) / 2,
                    'lower_radius': (left_circles['lower_circle']['radius'] + 
                                   right_circles['lower_circle']['radius']) / 2,
                    'vertical_distance': (left_circles['vertical_distance'] + 
                                        right_circles['vertical_distance']) / 2,
                    'radius_diff': (left_circles['radius_diff'] + 
                                  right_circles['radius_diff']) / 2,
                    'eye_height': (left_circles['eye_height'] + 
                                 right_circles['eye_height']) / 2,
                    'eye_width': (left_circles['eye_width'] + 
                                right_circles['eye_width']) / 2
                }
                self.current_blink_circles_data.append(avg_circles)
        
        # çŠ¶æ…‹é·ç§»
        if self.blink_state == self.STATE_OPEN:
            if ear < self.ear_threshold:
                # OPEN â†’ CLOSING
                self.blink_state = self.STATE_CLOSING
                self.t1 = current_time
                self.current_blink_circles_data = []
                self.current_blink_ear_history = []
                
        elif self.blink_state == self.STATE_CLOSING:
            if ear < self.ear_threshold * 0.8:
                # CLOSING â†’ CLOSED
                self.blink_state = self.STATE_CLOSED
                self.t2 = current_time
                
        elif self.blink_state == self.STATE_CLOSED:
            if ear > self.ear_threshold:
                # CLOSED â†’ OPENING
                self.blink_state = self.STATE_OPENING
                self.t3 = current_time
                
        elif self.blink_state == self.STATE_OPENING:
            if ear > self.ear_threshold * 1.2:
                # OPENING â†’ OPEN (ç¬ãå®Œäº†)
                self.blink_state = self.STATE_OPEN
                
                # 12æ¬¡å…ƒç‰¹å¾´é‡ã‚’æŠ½å‡º
                features = self.extract_blink_features_12d()
                
                # çµ±è¨ˆæ›´æ–°
                self.total_blinks += 1
                
                # ãƒªã‚»ãƒƒãƒˆ
                self.t1 = 0
                self.t2 = 0
                self.t3 = 0
                self.current_blink_circles_data = []
                self.current_blink_ear_history = []
                
                return features
        
        return None
    
    def extract_blink_features_12d(self):
        """
        ç¬ãå®Œäº†æ™‚ã«12æ¬¡å…ƒç‰¹å¾´é‡ã‚’æŠ½å‡º
        
        Returns:
            np.array: 12æ¬¡å…ƒç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«
                [0] closing_time: é–‰çœ¼æ™‚é–“
                [1] opening_time: é–‹çœ¼æ™‚é–“
                [2] blink_coefficient: ç¬ãä¿‚æ•° (opening_time / closing_time)
                [3] interval: å‰å›ã®ç¬ãã‹ã‚‰ã®é–“éš”
                [4] total_duration: ç·æŒç¶šæ™‚é–“
                [5] upper_radius_max: ä¸Šã¾ã¶ãŸå††ã®æœ€å¤§åŠå¾„
                [6] lower_radius_max: ä¸‹ã¾ã¶ãŸå††ã®æœ€å¤§åŠå¾„
                [7] vertical_distance_min: ä¸Šä¸‹å††ã®æœ€å°è·é›¢
                [8] radius_diff_max: åŠå¾„å·®ã®æœ€å¤§å€¤
                [9] eye_height_min: ç›®ã®é«˜ã•ã®æœ€å°å€¤
                [10] eye_width_avg: ç›®ã®å¹…ã®å¹³å‡å€¤
                [11] ear_min: EARã®æœ€å°å€¤
        """
        # Temporalç‰¹å¾´é‡ï¼ˆæ™‚é–“çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
        closing_time = self.t2 - self.t1 if self.t1 and self.t2 else 0.0
        opening_time = self.t3 - self.t2 if self.t2 and self.t3 else 0.0
        blink_coefficient = opening_time / closing_time if closing_time > 0 else 0.0
        total_duration = closing_time + opening_time
        
        # ç¬ãé–“éš”
        current_time = time.time()
        interval = current_time - self.last_blink_time if self.last_blink_time else 0.0
        self.last_blink_time = current_time
        
        # Spatialç‰¹å¾´é‡ï¼ˆç©ºé–“çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰- 2å††æ–¹å¼
        if len(self.current_blink_circles_data) > 0:
            # å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ±è¨ˆå€¤ã‚’è¨ˆç®—
            upper_radii = [d['upper_radius'] for d in self.current_blink_circles_data]
            lower_radii = [d['lower_radius'] for d in self.current_blink_circles_data]
            vertical_distances = [d['vertical_distance'] for d in self.current_blink_circles_data]
            radius_diffs = [d['radius_diff'] for d in self.current_blink_circles_data]
            eye_heights = [d['eye_height'] for d in self.current_blink_circles_data]
            eye_widths = [d['eye_width'] for d in self.current_blink_circles_data]
            
            upper_radius_max = max(upper_radii) if upper_radii else 0.0
            lower_radius_max = max(lower_radii) if lower_radii else 0.0
            vertical_distance_min = min(vertical_distances) if vertical_distances else 0.0
            radius_diff_max = max(radius_diffs) if radius_diffs else 0.0
            eye_height_min = min(eye_heights) if eye_heights else 0.0
            eye_width_avg = np.mean(eye_widths) if eye_widths else 0.0
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            upper_radius_max = 0.0
            lower_radius_max = 0.0
            vertical_distance_min = 0.0
            radius_diff_max = 0.0
            eye_height_min = 0.0
            eye_width_avg = 0.0
        
        # EARã®æœ€å°å€¤
        if len(self.current_blink_ear_history) > 0:
            ear_min = min(self.current_blink_ear_history)
        else:
            ear_min = 0.0
        
        # 12æ¬¡å…ƒç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«
        features = np.array([
            closing_time,           # [0]
            opening_time,           # [1]
            blink_coefficient,      # [2]
            interval,               # [3]
            total_duration,         # [4]
            upper_radius_max,       # [5]
            lower_radius_max,       # [6]
            vertical_distance_min,  # [7]
            radius_diff_max,        # [8]
            eye_height_min,         # [9]
            eye_width_avg,          # [10]
            ear_min                 # [11]
        ], dtype=np.float32)
        
        # ç¬ãå±¥æ­´ã«è¿½åŠ ï¼ˆçµæœä¿å­˜ç”¨ï¼‰
        self.blink_history.append({
            'timestamp': datetime.now().isoformat(),
            'blink_number': self.total_blinks + 1,
            'closing_time_ms': closing_time * 1000,
            'opening_time_ms': opening_time * 1000,
            'total_duration_ms': total_duration * 1000,
            'blink_coefficient': blink_coefficient,
            'interval_s': interval,
            'upper_radius_max': upper_radius_max,
            'lower_radius_max': lower_radius_max,
            'vertical_distance_min': vertical_distance_min,
            'radius_diff_max': radius_diff_max,
            'eye_height_min': eye_height_min,
            'eye_width_avg': eye_width_avg,
            'ear_min': ear_min
        })
        
        return features
    
    def predict_drowsiness(self):
        """
        çœ æ°—ã‚’æ¨å®š
        
        Returns:
            tuple: (äºˆæ¸¬ã‚¯ãƒ©ã‚¹, çœ æ°—ç¢ºç‡)
        """
        if len(self.feature_buffer) < self.sequence_length:
            return None, None
        
        # ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰æœ€æ–°ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å–å¾—
        sequence = np.array(list(self.feature_buffer), dtype=np.float32)
        sequence = sequence.reshape(1, self.sequence_length, -1)
        
        # PyTorchãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
        sequence_tensor = torch.FloatTensor(sequence).to(self.device)
        
        # æ¨è«–
        with torch.no_grad():
            output = self.model(sequence_tensor)
            probabilities = torch.softmax(output, dim=1)
            pred_class = torch.argmax(probabilities, dim=1).item()
            drowsy_prob = probabilities[0, 1].item()
        
        # çµ±è¨ˆæ›´æ–°
        if pred_class == 1:
            self.drowsy_count += 1
            self.consecutive_drowsy += 1
        else:
            self.normal_count += 1
            self.consecutive_drowsy = 0
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆåˆ¤å®š
        if self.consecutive_drowsy >= self.consecutive_drowsy_threshold:
            self.alert_active = True
        else:
            self.alert_active = False
        
        # æ¨å®šå±¥æ­´ã«è¿½åŠ ï¼ˆçµæœä¿å­˜ç”¨ï¼‰
        self.prediction_history.append({
            'timestamp': datetime.now().isoformat(),
            'predicted_class': pred_class,
            'drowsy_probability': drowsy_prob,
            'blink_count_at_prediction': self.total_blinks
        })
        
        return pred_class, drowsy_prob
    
    def process_frame(self, frame):
        """
        ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†
        
        Args:
            frame: å…¥åŠ›ãƒ•ãƒ¬ãƒ¼ãƒ 
            
        Returns:
            tuple: (å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ , EARå€¤, äºˆæ¸¬ã‚¯ãƒ©ã‚¹, çœ æ°—ç¢ºç‡)
        """
        self.frame_count += 1
        
        # RGBå¤‰æ›
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # MediaPipeã§é¡”æ¤œå‡º
        results = self.face_mesh.process(rgb_frame)
        
        if not results.multi_face_landmarks:
            return frame, None, None, None
        
        face_landmarks = results.multi_face_landmarks[0]
        h, w = frame.shape[:2]
        
        # ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’å–å¾—
        left_eye = [(int(face_landmarks.landmark[i].x * w),
                     int(face_landmarks.landmark[i].y * h))
                    for i in self.LEFT_EYE_INDICES]
        
        right_eye = [(int(face_landmarks.landmark[i].x * w),
                      int(face_landmarks.landmark[i].y * h))
                     for i in self.RIGHT_EYE_INDICES]
        
        # EARè¨ˆç®—
        left_ear = EARCalculator.calculate(left_eye)
        right_ear = EARCalculator.calculate(right_eye)
        avg_ear = (left_ear + right_ear) / 2.0
        
        # EARã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆ100ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ï¼‰
        if self.frame_count % 100 == 0:
            self.ear_samples.append({
                'timestamp': datetime.now().isoformat(),
                'frame': self.frame_count,
                'ear': avg_ear
            })
        
        # ç¬ãæ¤œå‡ºã¨ç‰¹å¾´é‡æŠ½å‡º
        blink_features = self.detect_blink(avg_ear, left_eye, right_eye)
        
        # ç‰¹å¾´é‡ã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
        if blink_features is not None:
            self.feature_buffer.append(blink_features)
        
        # çœ æ°—æ¨å®š
        pred_class, drowsy_prob = self.predict_drowsiness()
        
        # ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æç”»
        for point in left_eye:
            cv2.circle(frame, point, 2, (0, 255, 0), -1)
        for point in right_eye:
            cv2.circle(frame, point, 2, (255, 0, 0), -1)
        
        # 2å††ã®æç”»ï¼ˆè¦–è¦šåŒ–ï¼‰
        left_circles = TwoCircleFitter.fit_eyelids(left_eye)
        right_circles = TwoCircleFitter.fit_eyelids(right_eye)
        
        # å·¦ç›®ã®2å††ã‚’æç”»
        if left_circles:
            try:
                # ä¸Šã¾ã¶ãŸå††ï¼ˆã‚·ã‚¢ãƒ³è‰²ï¼‰
                upper_center = (int(left_circles['upper_circle']['center_x']),
                              int(left_circles['upper_circle']['center_y']))
                upper_radius = int(left_circles['upper_circle']['radius'])
                cv2.circle(frame, upper_center, upper_radius, (255, 255, 0), 2)
                
                # ä¸‹ã¾ã¶ãŸå††ï¼ˆé»„è‰²ï¼‰
                lower_center = (int(left_circles['lower_circle']['center_x']),
                              int(left_circles['lower_circle']['center_y']))
                lower_radius = int(left_circles['lower_circle']['radius'])
                cv2.circle(frame, lower_center, lower_radius, (0, 255, 255), 2)
            except:
                pass
        
        # å³ç›®ã®2å††ã‚’æç”»
        if right_circles:
            try:
                # ä¸Šã¾ã¶ãŸå††ï¼ˆã‚·ã‚¢ãƒ³è‰²ï¼‰
                upper_center = (int(right_circles['upper_circle']['center_x']),
                              int(right_circles['upper_circle']['center_y']))
                upper_radius = int(right_circles['upper_circle']['radius'])
                cv2.circle(frame, upper_center, upper_radius, (255, 255, 0), 2)
                
                # ä¸‹ã¾ã¶ãŸå††ï¼ˆé»„è‰²ï¼‰
                lower_center = (int(right_circles['lower_circle']['center_x']),
                              int(right_circles['lower_circle']['center_y']))
                lower_radius = int(right_circles['lower_circle']['radius'])
                cv2.circle(frame, lower_center, lower_radius, (0, 255, 255), 2)
            except:
                pass
        
        # æƒ…å ±è¡¨ç¤º
        cv2.putText(frame, f"EAR: {avg_ear:.3f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.putText(frame, f"Blinks: {self.total_blinks}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.putText(frame, f"Buffer: {len(self.feature_buffer)}/{self.sequence_length}", 
                    (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        if pred_class is not None:
            status = "DROWSY" if pred_class == 1 else "NORMAL"
            color = (0, 0, 255) if pred_class == 1 else (0, 255, 0)
            
            cv2.putText(frame, f"Status: {status}", (10, 120),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            
            cv2.putText(frame, f"Drowsy Prob: {drowsy_prob:.2%}", (10, 150),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆè¡¨ç¤º
            if self.alert_active:
                cv2.rectangle(frame, (0, 0), (w, h), (0, 0, 255), 10)
                cv2.putText(frame, "!!! ALERT: DROWSY !!!", (w//4, h//2),
                            cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
        
        return frame, avg_ear, pred_class, drowsy_prob
    
    def get_statistics(self):
        """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        total_predictions = self.drowsy_count + self.normal_count
        
        return {
            'total_blinks': self.total_blinks,
            'total_predictions': total_predictions,
            'drowsy_count': self.drowsy_count,
            'normal_count': self.normal_count,
            'drowsy_percentage': (self.drowsy_count / total_predictions * 100) if total_predictions > 0 else 0,
            'alert_active': self.alert_active
        }
    
    def save_results(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        session_end_time = datetime.now()
        duration = (session_end_time - self.session_start_time).total_seconds()
        
        # çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
        total_predictions = self.drowsy_count + self.normal_count
        
        # ç¬ãçµ±è¨ˆ
        blink_stats = {}
        if len(self.blink_history) > 0:
            closing_times = [b['closing_time_ms'] for b in self.blink_history]
            opening_times = [b['opening_time_ms'] for b in self.blink_history]
            total_durations = [b['total_duration_ms'] for b in self.blink_history]
            coefficients = [b['blink_coefficient'] for b in self.blink_history]
            intervals = [b['interval_s'] for b in self.blink_history if b['interval_s'] > 0]
            
            blink_stats = {
                'closing_time_ms': {
                    'mean': np.mean(closing_times),
                    'std': np.std(closing_times),
                    'min': np.min(closing_times),
                    'max': np.max(closing_times)
                },
                'opening_time_ms': {
                    'mean': np.mean(opening_times),
                    'std': np.std(opening_times),
                    'min': np.min(opening_times),
                    'max': np.max(opening_times)
                },
                'total_duration_ms': {
                    'mean': np.mean(total_durations),
                    'std': np.std(total_durations),
                    'min': np.min(total_durations),
                    'max': np.max(total_durations)
                },
                'blink_coefficient': {
                    'mean': np.mean(coefficients),
                    'std': np.std(coefficients),
                    'min': np.min(coefficients),
                    'max': np.max(coefficients)
                },
                'interval_s': {
                    'mean': np.mean(intervals) if intervals else 0,
                    'std': np.std(intervals) if intervals else 0,
                    'min': np.min(intervals) if intervals else 0,
                    'max': np.max(intervals) if intervals else 0
                }
            }
        
        # çµæœãƒ‡ãƒ¼ã‚¿
        result = {
            'session_info': {
                'start_time': self.session_start_time.isoformat(),
                'end_time': session_end_time.isoformat(),
                'duration_seconds': duration,
                'model_path': self.model_path,
                'ear_threshold': self.ear_threshold,
                'sequence_length': self.sequence_length
            },
            'statistics': {
                'total_frames': self.frame_count,
                'total_blinks': self.total_blinks,
                'total_predictions': total_predictions,
                'normal_predictions': self.normal_count,
                'drowsy_predictions': self.drowsy_count,
                'drowsy_ratio': self.drowsy_count / total_predictions if total_predictions > 0 else 0,
                'blinks_per_minute': self.total_blinks / (duration / 60) if duration > 0 else 0,
                'average_blink_interval': np.mean([b['interval_s'] for b in self.blink_history if b['interval_s'] > 0]) if self.blink_history else 0
            },
            'blink_statistics': blink_stats,
            'blink_history': self.blink_history,
            'prediction_history': self.prediction_history,
            'ear_samples': self.ear_samples
        }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
        filename = f"session_{self.session_start_time.strftime('%Y%m%d_%H%M%S')}.json"
        filepath = os.path.join(self.output_dir, filename)
        
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
        
        return filepath
    
    def run(self, camera_id=0):
        """
        ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œ
        
        Args:
            camera_id: ã‚«ãƒ¡ãƒ©ID
        """
        # ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–
        print("\nğŸ¥ ã‚«ãƒ¡ãƒ©èµ·å‹•")
        cap = cv2.VideoCapture(camera_id)
        
        if not cap.isOpened():
            print("âŒ ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        # ã‚«ãƒ¡ãƒ©è¨­å®š
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, 30)
        
        print("   'q' ã‚­ãƒ¼ã§çµ‚äº†")
        print("   's' ã‚­ãƒ¼ã§é€”ä¸­ä¿å­˜")
        print("   'r' ã‚­ãƒ¼ã§çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ")
        print("=" * 70)
        
        # FPSè¨ˆæ¸¬ç”¨
        fps_start_time = time.time()
        fps_frame_count = 0
        fps = 0
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    print("âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    break
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
                processed_frame, ear, pred_class, drowsy_prob = self.process_frame(frame)
                
                # FPSè¨ˆç®—
                fps_frame_count += 1
                if fps_frame_count >= 30:
                    fps = fps_frame_count / (time.time() - fps_start_time)
                    fps_start_time = time.time()
                    fps_frame_count = 0
                
                # FPSè¡¨ç¤º
                cv2.putText(processed_frame, f"FPS: {fps:.1f}", (10, 180),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
                cv2.imshow('Drowsiness Detection (12D Features)', processed_frame)
                
                # ã‚­ãƒ¼å…¥åŠ›å‡¦ç†
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord('q') or key == 27:  # q or ESC
                    break
                elif key == ord('s'):  # s - é€”ä¸­ä¿å­˜
                    self.save_results()
                elif key == ord('r'):  # r - ãƒªã‚»ãƒƒãƒˆ
                    self.total_blinks = 0
                    self.drowsy_count = 0
                    self.normal_count = 0
                    self.consecutive_drowsy = 0
                    self.alert_active = False
                    self.blink_history = []
                    self.prediction_history = []
                    print("\nâœ… çµ±è¨ˆã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ\n")
        
        except KeyboardInterrupt:
            print("\n\nâš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        
        finally:
            # æœ€çµ‚çµ±è¨ˆè¡¨ç¤º
            stats = self.get_statistics()
            print("\n" + "=" * 70)
            print("ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ")
            print("=" * 70)
            print(f"ç·ç¬ãæ•°: {stats['total_blinks']}")
            print(f"çœ æ°—æ¤œå‡ºå›æ•°: {stats['drowsy_count']}")
            print(f"æ­£å¸¸æ¤œå‡ºå›æ•°: {stats['normal_count']}")
            print(f"çœ æ°—å‰²åˆ: {stats['drowsy_percentage']:.1f}%")
            print("=" * 70)
            
            # çµæœã‚’ä¿å­˜
            filepath = self.save_results()
            print(f"\nâœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
            
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            cap.release()
            cv2.destroyAllWindows()


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¨å®šã‚·ã‚¹ãƒ†ãƒ  (12æ¬¡å…ƒç‰¹å¾´é‡ãƒ»çµæœä¿å­˜æ©Ÿèƒ½ä»˜ã)')
    parser.add_argument('--model-path', type=str, required=True,
                        help='å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--sequence-length', type=int, default=10,
                        help='LSTMã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·')
    parser.add_argument('--ear-threshold', type=float, default=0.21,
                        help='EARé–¾å€¤')
    parser.add_argument('--camera-id', type=int, default=0,
                        help='ã‚«ãƒ¡ãƒ©ID')
    parser.add_argument('--output-dir', type=str, default='drowsiness_results',
                        help='çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    
    args = parser.parse_args()
    
    print("=" * 70)
    print("ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ï¼ˆ12æ¬¡å…ƒãƒ»çµæœä¿å­˜æ©Ÿèƒ½ä»˜ãï¼‰")
    print("=" * 70)
    print(f"ğŸ“ ãƒ¢ãƒ‡ãƒ«: {args.model_path}")
    print(f"ğŸ“Š ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·: {args.sequence_length}")
    print(f"ğŸ‘ï¸ EARé–¾å€¤: {args.ear_threshold}")
    print(f"ğŸ’¾ çµæœä¿å­˜å…ˆ: {args.output_dir}")
    print("=" * 70)
    
    detector = RealtimeDrowsinessDetector(
        model_path=args.model_path,
        sequence_length=args.sequence_length,
        ear_threshold=args.ear_threshold,
        output_dir=args.output_dir
    )
    
    detector.run(camera_id=args.camera_id)


if __name__ == "__main__":
    main()
