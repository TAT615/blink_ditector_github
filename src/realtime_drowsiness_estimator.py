"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ï¼ˆ2å††æ–¹å¼ãƒ»12æ¬¡å…ƒç‰¹å¾´é‡å¯¾å¿œï¼‰

ã‚«ãƒ¡ãƒ©ã§é¡”ã‚’æ’®å½±ã—ã€ç¬ããƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰çœ æ°—çŠ¶æ…‹ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§åˆ¤å®šã—ã¾ã™ã€‚

ä½¿ã„æ–¹:
    python realtime_drowsiness_estimator.py --model-path trained_models/drowsiness_lstm_20251115_224046.pth
"""

import cv2
import mediapipe as mp
import numpy as np
import torch
import argparse
import time
from collections import deque
from datetime import datetime

# LSTMãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from src.lstm_drowsiness_model import DrowsinessEstimator, DrowsinessLSTM
except ImportError:
    print("âš ï¸ src/lstm_drowsiness_model.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    print("   ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„")


class EARCalculator:
    """Eye Aspect Ratioï¼ˆEARï¼‰è¨ˆç®—å™¨"""
    
    @staticmethod
    def calculate(eye_landmarks):
        """
        EARã‚’è¨ˆç®—
        
        Args:
            eye_landmarks: ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™ãƒªã‚¹ãƒˆ [(x, y), ...]
            
        Returns:
            float: EARå€¤
        """
        # å‚ç›´è·é›¢
        v1 = np.linalg.norm(np.array(eye_landmarks[1]) - np.array(eye_landmarks[5]))
        v2 = np.linalg.norm(np.array(eye_landmarks[2]) - np.array(eye_landmarks[4]))
        
        # æ°´å¹³è·é›¢
        h = np.linalg.norm(np.array(eye_landmarks[0]) - np.array(eye_landmarks[3]))
        
        # EARè¨ˆç®—
        ear = (v1 + v2) / (2.0 * h)
        return ear


class TwoCircleFitter:
    """2å††ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ï¼ˆä¸Šã¾ã¶ãŸãƒ»ä¸‹ã¾ã¶ãŸï¼‰"""
    
    @staticmethod
    def fit_circle(points):
        """
        3ç‚¹ã‹ã‚‰å††ã‚’ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
        
        Args:
            points: [(x, y), (x, y), (x, y)]
            
        Returns:
            tuple: (center_x, center_y, radius) ã¾ãŸã¯ None
        """
        if len(points) != 3:
            return None
        
        try:
            points = np.array(points, dtype=np.float32)
            
            # è¡Œåˆ—Aã¨ãƒ™ã‚¯ãƒˆãƒ«bã‚’æ§‹ç¯‰
            A = np.zeros((3, 3))
            b = np.zeros(3)
            
            for i in range(3):
                x, y = points[i]
                A[i] = [2*x, 2*y, 1]
                b[i] = x*x + y*y
            
            # é€£ç«‹æ–¹ç¨‹å¼ã‚’è§£ã
            params = np.linalg.solve(A, b)
            
            center_x = params[0]
            center_y = params[1]
            radius = np.sqrt(params[2] + center_x**2 + center_y**2)
            
            return center_x, center_y, radius
            
        except:
            return None
    
    @staticmethod
    def fit_eyelids(eye_landmarks):
        """
        ä¸Šã¾ã¶ãŸãƒ»ä¸‹ã¾ã¶ãŸã®å††ã‚’ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
        
        Args:
            eye_landmarks: ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™ãƒªã‚¹ãƒˆ
            
        Returns:
            tuple: ((c1_x, c1_y, c1_r), (c2_x, c2_y, c2_r)) ã¾ãŸã¯ (None, None)
        """
        if len(eye_landmarks) < 6:
            return None, None
        
        # ä¸Šã¾ã¶ãŸ3ç‚¹
        upper_points = [eye_landmarks[1], eye_landmarks[2], eye_landmarks[5]]
        c1 = TwoCircleFitter.fit_circle(upper_points)
        
        # ä¸‹ã¾ã¶ãŸ3ç‚¹
        lower_points = [eye_landmarks[3], eye_landmarks[4], eye_landmarks[5]]
        c2 = TwoCircleFitter.fit_circle(lower_points)
        
        return c1, c2


class RealtimeDrowsinessDetector:
    """
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ 
    """
    
    # MediaPipe Face Meshã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    LEFT_EYE_INDICES = [33, 160, 158, 133, 153, 144]
    RIGHT_EYE_INDICES = [362, 385, 387, 263, 373, 380]
    
    # ç¬ãçŠ¶æ…‹
    STATE_OPEN = 0
    STATE_CLOSING = 1
    STATE_CLOSED = 2
    STATE_OPENING = 3
    
    def __init__(self, model_path, sequence_length=10, ear_threshold=0.21):
        """
        åˆæœŸåŒ–
        
        Args:
            model_path (str): å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
            sequence_length (int): LSTMã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·
            ear_threshold (float): EARé–¾å€¤
        """
        self.sequence_length = sequence_length
        self.ear_threshold = ear_threshold
        
        # MediaPipe Face Mesh
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        
        # ç¬ãæ¤œå‡ºç”¨
        self.blink_state = self.STATE_OPEN
        self.state_start_time = time.time()
        self.t1 = 0  # OPEN â†’ CLOSING
        self.t2 = 0  # CLOSING â†’ CLOSED
        self.t3 = 0  # CLOSED â†’ OPENING
        
        # ç‰¹å¾´é‡ãƒãƒƒãƒ•ã‚¡ï¼ˆã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”¨ï¼‰
        self.feature_buffer = deque(maxlen=sequence_length)
        
        # LSTMãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        self.estimator = DrowsinessEstimator()
        self.estimator.load_model(model_path)
        self.estimator.model.eval()
        
        # æ¨å®šçµæœ
        self.current_prediction = None
        self.current_probability = None
        
        # çµ±è¨ˆ
        self.total_blinks = 0
        self.drowsy_count = 0
        
        print("=" * 70)
        print("ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•")
        print("=" * 70)
        print(f"ğŸ“ ãƒ¢ãƒ‡ãƒ«: {model_path}")
        print(f"ğŸ“Š ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·: {sequence_length}")
        print(f"ğŸ‘ï¸ EARé–¾å€¤: {ear_threshold}")
        print("=" * 70)
    
    def extract_eye_landmarks(self, face_landmarks, image_width, image_height, eye_indices):
        """
        ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æŠ½å‡º
        
        Args:
            face_landmarks: MediaPipeã®é¡”ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            image_width: ç”»åƒå¹…
            image_height: ç”»åƒé«˜ã•
            eye_indices: ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            
        Returns:
            list: [(x, y), ...] ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™
        """
        landmarks = []
        for idx in eye_indices:
            landmark = face_landmarks.landmark[idx]
            x = landmark.x * image_width
            y = landmark.y * image_height
            landmarks.append((x, y))
        return landmarks
    
    def detect_blink(self, left_ear, right_ear, left_eye_landmarks, right_eye_landmarks):
        """
        ç¬ãã‚’æ¤œå‡ºã—ã€å®Œäº†æ™‚ã«ç‰¹å¾´é‡ã‚’æŠ½å‡º
        
        Args:
            left_ear: å·¦ç›®ã®EAR
            right_ear: å³ç›®ã®EAR
            left_eye_landmarks: å·¦ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            right_eye_landmarks: å³ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            
        Returns:
            dict: ç¬ãæƒ…å ±ï¼ˆå®Œäº†æ™‚ã®ã¿ï¼‰ ã¾ãŸã¯ None
        """
        avg_ear = (left_ear + right_ear) / 2.0
        current_time = time.time()
        
        # çŠ¶æ…‹é·ç§»
        if self.blink_state == self.STATE_OPEN:
            if avg_ear < self.ear_threshold:
                self.blink_state = self.STATE_CLOSING
                self.t1 = current_time
                self.state_start_time = current_time
        
        elif self.blink_state == self.STATE_CLOSING:
            if avg_ear >= self.ear_threshold:
                # ç¬ãã‚­ãƒ£ãƒ³ã‚»ãƒ«
                self.blink_state = self.STATE_OPEN
            else:
                closing_time = current_time - self.state_start_time
                if closing_time >= 0.01:  # 10msä»¥ä¸Š
                    self.blink_state = self.STATE_CLOSED
                    self.t2 = current_time
                    self.state_start_time = current_time
        
        elif self.blink_state == self.STATE_CLOSED:
            if avg_ear >= self.ear_threshold:
                self.blink_state = self.STATE_OPENING
                self.t3 = current_time
                self.state_start_time = current_time
        
        elif self.blink_state == self.STATE_OPENING:
            opening_time = current_time - self.state_start_time
            if opening_time >= 0.01:  # 10msä»¥ä¸Š
                # ç¬ãå®Œäº†
                self.blink_state = self.STATE_OPEN
                
                # ç‰¹å¾´é‡ã‚’æŠ½å‡º
                features = self.extract_blink_features(
                    left_eye_landmarks, 
                    right_eye_landmarks
                )
                
                if features is not None:
                    self.total_blinks += 1
                    return features
        
        return None
    
    def extract_blink_features(self, left_eye_landmarks, right_eye_landmarks):
        """
        ç¬ãå®Œäº†æ™‚ã«12æ¬¡å…ƒç‰¹å¾´é‡ã‚’æŠ½å‡º
        
        Returns:
            np.array: 12æ¬¡å…ƒç‰¹å¾´é‡ ã¾ãŸã¯ None
        """
        try:
            # æ™‚é–“è¨ˆç®—
            closing_time = self.t2 - self.t1
            opening_time = time.time() - self.t3
            total_duration = closing_time + opening_time
            blink_coefficient = opening_time / closing_time if closing_time > 0 else 0
            
            # æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
            if not (0.025 <= closing_time <= 1.0):
                return None
            if not (0.05 <= opening_time <= 0.6):
                return None
            if not (0.5 <= blink_coefficient <= 8.0):
                return None
            
            # 2å††ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            c1_left, c2_left = TwoCircleFitter.fit_eyelids(left_eye_landmarks)
            c1_right, c2_right = TwoCircleFitter.fit_eyelids(right_eye_landmarks)
            
            # ä¸¡ç›®ã®å¹³å‡
            if c1_left and c1_right and c2_left and c2_right:
                c1_center_x = (c1_left[0] + c1_right[0]) / 2.0
                c1_center_y = (c1_left[1] + c1_right[1]) / 2.0
                c1_radius = (c1_left[2] + c1_right[2]) / 2.0
                c2_center_x = (c2_left[0] + c2_right[0]) / 2.0
                c2_center_y = (c2_left[1] + c2_right[1]) / 2.0
                c2_radius = (c2_left[2] + c2_right[2]) / 2.0
            else:
                # 2å††ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å¤±æ•—æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                c1_center_x = c1_center_y = c1_radius = 0.0
                c2_center_x = c2_center_y = c2_radius = 0.0
            
            # 12æ¬¡å…ƒç‰¹å¾´é‡
            features = np.array([
                closing_time,
                opening_time,
                blink_coefficient,
                self.t1,           # timestamp
                total_duration,
                0.0,               # intervalï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã¯è¨ˆç®—å›°é›£ï¼‰
                c1_center_x,
                c1_center_y,
                c1_radius,
                c2_center_x,
                c2_center_y,
                c2_radius
            ], dtype=np.float32)
            
            return features
            
        except Exception as e:
            print(f"âš ï¸ ç‰¹å¾´é‡æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def predict_drowsiness(self):
        """
        LSTMãƒ¢ãƒ‡ãƒ«ã§çœ æ°—ã‚’æ¨å®š
        
        Returns:
            tuple: (prediction, probability) ã¾ãŸã¯ (None, None)
        """
        if len(self.feature_buffer) < self.sequence_length:
            return None, None
        
        try:
            # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ä½œæˆ
            sequence = np.array(list(self.feature_buffer))
            sequence = sequence.reshape(1, self.sequence_length, -1)
            
            # æ¨è«–
            proba = self.estimator.predict_proba(sequence)
            prediction = np.argmax(proba[0])
            probability = proba[0][prediction]
            
            return prediction, probability
            
        except Exception as e:
            print(f"âš ï¸ æ¨è«–ã‚¨ãƒ©ãƒ¼: {e}")
            return None, None
    
    def draw_info(self, frame, left_ear, right_ear):
        """
        ç”»é¢ã«æƒ…å ±ã‚’è¡¨ç¤º
        
        Args:
            frame: ç”»åƒãƒ•ãƒ¬ãƒ¼ãƒ 
            left_ear: å·¦ç›®ã®EAR
            right_ear: å³ç›®ã®EAR
        """
        height, width = frame.shape[:2]
        avg_ear = (left_ear + right_ear) / 2.0
        
        # èƒŒæ™¯ï¼ˆåŠé€æ˜é»’ï¼‰
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (width - 10, 180), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)
        
        # EARæƒ…å ±
        cv2.putText(frame, f"EAR: {avg_ear:.3f}", (20, 40),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ç¬ãå›æ•°
        cv2.putText(frame, f"Blinks: {self.total_blinks}", (20, 70),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ãƒãƒƒãƒ•ã‚¡çŠ¶æ…‹
        buffer_status = f"Buffer: {len(self.feature_buffer)}/{self.sequence_length}"
        cv2.putText(frame, buffer_status, (20, 100),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # çœ æ°—åˆ¤å®š
        if self.current_prediction is not None:
            if self.current_prediction == 0:
                label = "Normal"
                color = (0, 255, 0)  # ç·‘
            else:
                label = "DROWSY!"
                color = (0, 0, 255)  # èµ¤
                self.drowsy_count += 1
            
            # ãƒ©ãƒ™ãƒ«è¡¨ç¤º
            cv2.putText(frame, label, (20, 140),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 3)
            
            # ç¢ºç‡è¡¨ç¤º
            prob_text = f"Confidence: {self.current_probability:.1%}"
            cv2.putText(frame, prob_text, (20, 170),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        else:
            cv2.putText(frame, "Collecting data...", (20, 140),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
        
        # è­¦å‘Šè¡¨ç¤º
        if self.current_prediction == 1:
            # ç”»é¢ä¸Šéƒ¨ã«å¤§ããè­¦å‘Š
            warning_text = "!!! DROWSINESS DETECTED !!!"
            text_size = cv2.getTextSize(warning_text, cv2.FONT_HERSHEY_SIMPLEX, 1.5, 3)[0]
            text_x = (width - text_size[0]) // 2
            cv2.putText(frame, warning_text, (text_x, 50),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
    
    def run(self):
        """
        ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œçŸ¥ã‚’å®Ÿè¡Œ
        """
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            print("âŒ ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“")
            return
        
        print("\nğŸ¥ ã‚«ãƒ¡ãƒ©èµ·å‹•")
        print("   'q' ã‚­ãƒ¼ã§çµ‚äº†")
        print("=" * 70)
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # å·¦å³åè»¢ï¼ˆé¡åƒï¼‰
                frame = cv2.flip(frame, 1)
                
                # RGBå¤‰æ›
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # é¡”æ¤œå‡º
                results = self.face_mesh.process(rgb_frame)
                
                if results.multi_face_landmarks:
                    face_landmarks = results.multi_face_landmarks[0]
                    height, width, _ = frame.shape
                    
                    # ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æŠ½å‡º
                    left_eye = self.extract_eye_landmarks(
                        face_landmarks, width, height, self.LEFT_EYE_INDICES
                    )
                    right_eye = self.extract_eye_landmarks(
                        face_landmarks, width, height, self.RIGHT_EYE_INDICES
                    )
                    
                    # EARè¨ˆç®—
                    left_ear = EARCalculator.calculate(left_eye)
                    right_ear = EARCalculator.calculate(right_eye)
                    
                    # ç¬ãæ¤œå‡º
                    blink_features = self.detect_blink(
                        left_ear, right_ear, left_eye, right_eye
                    )
                    
                    if blink_features is not None:
                        # ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
                        self.feature_buffer.append(blink_features)
                        
                        # çœ æ°—æ¨å®š
                        pred, prob = self.predict_drowsiness()
                        if pred is not None:
                            self.current_prediction = pred
                            self.current_probability = prob
                    
                    # æƒ…å ±è¡¨ç¤º
                    self.draw_info(frame, left_ear, right_ear)
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
                cv2.imshow('Drowsiness Detection', frame)
                
                # 'q'ã‚­ãƒ¼ã§çµ‚äº†
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
        
        finally:
            cap.release()
            cv2.destroyAllWindows()
            
            # çµ±è¨ˆè¡¨ç¤º
            print("\n" + "=" * 70)
            print("ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ")
            print("=" * 70)
            print(f"ç·ç¬ãæ•°: {self.total_blinks}")
            print(f"çœ æ°—æ¤œå‡ºå›æ•°: {self.drowsy_count}")
            if self.total_blinks > 0:
                drowsy_rate = (self.drowsy_count / self.total_blinks) * 100
                print(f"çœ æ°—æ¤œå‡ºç‡: {drowsy_rate:.1f}%")
            print("=" * 70)


def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    parser = argparse.ArgumentParser(
        description='ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    parser.add_argument('--model-path', type=str, 
                       default='trained_models/drowsiness_lstm_20251115_224046.pth',
                       help='å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--sequence-length', type=int, default=10,
                       help='LSTMã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·')
    parser.add_argument('--ear-threshold', type=float, default=0.21,
                       help='EARé–¾å€¤')
    
    args = parser.parse_args()
    
    # ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•
    detector = RealtimeDrowsinessDetector(
        model_path=args.model_path,
        sequence_length=args.sequence_length,
        ear_threshold=args.ear_threshold
    )
    
    detector.run()


if __name__ == "__main__":
    main()