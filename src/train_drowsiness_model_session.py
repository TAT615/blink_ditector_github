"""
çœ æ°—æ¨å®šLSTMãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½åˆ†å‰²å¯¾å¿œç‰ˆï¼‰
Drowsiness Estimation LSTM Model Training Script with Session-based Splitting

ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã‚’é˜²ããŸã‚ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã§ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã¦è¨“ç·´ã—ã¾ã™ã€‚

ä½¿ã„æ–¹:
    python train_drowsiness_model_session.py --data-dir data --epochs 100
"""

import os
import sys
import json
import argparse
import numpy as np
from datetime import datetime
from typing import Dict, Optional

# ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# å†…éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
try:
    from drowsiness_data_manager import DrowsinessDataManager
    from src.lstm_drowsiness_model import DrowsinessEstimator
except ImportError:
    try:
        from src.drowsiness_data_manager import DrowsinessDataManager
        from src.lstm_drowsiness_model import DrowsinessEstimator
    except ImportError as e:
        print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print("   å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)

# å¯è¦–åŒ–
try:
    import matplotlib.pyplot as plt
    import matplotlib
    matplotlib.use('Agg')  # GUIãªã—ã§å‹•ä½œ
    HAS_MATPLOTLIB = True
except ImportError:
    HAS_MATPLOTLIB = False
    print("âš ï¸ matplotlibãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚°ãƒ©ãƒ•ã¯ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã€‚")


class ModelTrainerSessionBased:
    """
    çœ æ°—æ¨å®šãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½åˆ†å‰²å¯¾å¿œç‰ˆï¼‰
    
    ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã‚’é˜²ããŸã‚ã€åŒã˜ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¯
    å…¨ã¦åŒã˜ã‚»ãƒƒãƒˆï¼ˆè¨“ç·´/æ¤œè¨¼/ãƒ†ã‚¹ãƒˆï¼‰ã«é…ç½®ã•ã‚Œã¾ã™ã€‚
    """
    
    def __init__(self, config: Dict):
        """
        åˆæœŸåŒ–
        
        Args:
            config (Dict): è¨“ç·´è¨­å®š
        """
        self.config = config
        self.data_manager = None
        self.estimator = None
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.output_dir = config.get('output_dir', 'trained_models')
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, 'logs'), exist_ok=True)
        
        # ãƒ¢ãƒ‡ãƒ«åï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.model_name = f"drowsiness_lstm_{timestamp}"
        
        print("=" * 70)
        print("ğŸ“ ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½åˆ†å‰²å¯¾å¿œç‰ˆï¼‰")
        print("=" * 70)
        print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
        print(f"ğŸ·ï¸  ãƒ¢ãƒ‡ãƒ«å: {self.model_name}")
    
    def load_data(self, data_dir: str) -> bool:
        """
        ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã§åˆ†å‰²
        
        Args:
            data_dir (str): ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            bool: æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        print("\n" + "=" * 70)
        print("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½åˆ†å‰²ï¼‰")
        print("=" * 70)
        
        try:
            self.data_manager = DrowsinessDataManager(data_dir)
            
            # ç”Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰èª­ã¿è¾¼ã¿
            print("ğŸ“Š ç”Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰èª­ã¿è¾¼ã¿...")
            success = self.data_manager.load_all_data(verbose=True)
            
            if not success:
                print("âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—")
                return False
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã§ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰
            print("\nğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã§ãƒ‡ãƒ¼ã‚¿åˆ†å‰²...")
            self.data_manager.split_data_by_session(
                train_ratio=self.config.get('train_ratio', 0.7),
                val_ratio=self.config.get('val_ratio', 0.15),
                test_ratio=self.config.get('test_ratio', 0.15),
                verbose=True
            )
            
            # æ­£è¦åŒ–
            print("\nğŸ”§ ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–...")
            self.data_manager.normalize_data(
                method=self.config.get('normalization', 'zscore'),
                verbose=True
            )
            
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¿å­˜
            dataset_file = os.path.join(data_dir, 'drowsiness_dataset_session_split.npz')
            self.data_manager.export_dataset(dataset_file)
            
            # æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¿å­˜
            norm_params_file = os.path.join(data_dir, 'normalization_params.json')
            self.data_manager.save_normalization_params(norm_params_file)
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def create_model(self):
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
        """
        print("\n" + "=" * 70)
        print("ğŸ§  ãƒ¢ãƒ‡ãƒ«ä½œæˆ")
        print("=" * 70)
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        model_params = {
            'input_size': self.config.get('input_size', 12),
            'hidden_size1': self.config.get('hidden_size1', 64),
            'hidden_size2': self.config.get('hidden_size2', 32),
            'fc_size': self.config.get('fc_size', 32),
            'num_classes': self.config.get('num_classes', 2),
            'dropout_rate': self.config.get('dropout_rate', 0.3)
        }
        
        # æ¨å®šå™¨ä½œæˆ
        self.estimator = DrowsinessEstimator(
            model_params=model_params,
            device=self.config.get('device', None)
        )
        
        self.estimator.get_model_summary()
    
    def train_model(self) -> bool:
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
        
        Returns:
            bool: æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        if self.data_manager is None:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        print("\n" + "=" * 70)
        print("ğŸš€ ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹")
        print("=" * 70)
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        train_sequences, train_labels = self.data_manager.get_train_data()
        val_sequences, val_labels = self.data_manager.get_val_data()
        
        if len(train_sequences) == 0:
            print("âŒ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return False
        
        # è¨“ç·´
        import time
        start_time = time.time()
        
        history = self.estimator.train_model(
            train_sequences=train_sequences,
            train_labels=train_labels,
            val_sequences=val_sequences,
            val_labels=val_labels,
            epochs=self.config.get('epochs', 100),
            batch_size=self.config.get('batch_size', 32),
            learning_rate=self.config.get('learning_rate', 0.001),
            patience=self.config.get('patience', 10),
            verbose=True
        )
        
        self.training_time = time.time() - start_time
        
        print(f"\nâ±ï¸  è¨“ç·´æ™‚é–“: {self.training_time:.1f}ç§’")
        print(f"ğŸ¯ ãƒ™ã‚¹ãƒˆæ¤œè¨¼ç²¾åº¦: {max(history['val_acc']):.2f}%")
        
        return True
    
    def plot_training_history(self):
        """è¨“ç·´å±¥æ­´ã‚’å¯è¦–åŒ–"""
        if not HAS_MATPLOTLIB:
            return
        
        print("\n" + "=" * 70)
        print("ğŸ“Š è¨“ç·´å±¥æ­´ã®å¯è¦–åŒ–")
        print("=" * 70)
        
        history = self.estimator.history
        
        fig, axes = plt.subplots(1, 2, figsize=(12, 4))
        
        # æå¤±
        axes[0].plot(history['train_loss'], label='Train Loss')
        axes[0].plot(history['val_loss'], label='Val Loss')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Loss')
        axes[0].set_title('Loss (Session-based Split)')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        
        # ç²¾åº¦
        axes[1].plot(history['train_acc'], label='Train Acc')
        axes[1].plot(history['val_acc'], label='Val Acc')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('Accuracy (%)')
        axes[1].set_title('Accuracy (Session-based Split)')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜
        plot_path = os.path.join(
            self.output_dir, 'logs', f"{self.model_name}_history.png"
        )
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… è¨“ç·´å±¥æ­´ã‚°ãƒ©ãƒ•ä¿å­˜: {plot_path}")
    
    def evaluate_model(self) -> Optional[Dict]:
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
        
        Returns:
            Dict: è©•ä¾¡çµæœ
        """
        print("\n" + "=" * 70)
        print("ğŸ“Š ãƒ¢ãƒ‡ãƒ«è©•ä¾¡")
        print("=" * 70)
        
        test_sequences, test_labels = self.data_manager.get_test_data()
        
        if len(test_sequences) == 0:
            print("âš ï¸ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return None
        
        # äºˆæ¸¬
        predictions = self.estimator.predict(test_sequences)
        
        # ç²¾åº¦è¨ˆç®—
        accuracy = np.mean(predictions == test_labels) * 100
        
        # æ··åŒè¡Œåˆ—
        from sklearn.metrics import confusion_matrix, classification_report
        cm = confusion_matrix(test_labels, predictions)
        
        # åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ
        target_names = ['Normal', 'Drowsy']
        report = classification_report(
            test_labels, predictions,
            target_names=target_names,
            output_dict=True
        )
        
        print(f"\nğŸ“Š è©•ä¾¡çµæœ:")
        print(f"   æ­£è§£ç‡: {accuracy:.2f}%")
        print(f"\næ··åŒè¡Œåˆ—:")
        print(f"              äºˆæ¸¬: Normal  Drowsy")
        print(f"   å®Ÿéš›: Normal    {cm[0][0]:5d}   {cm[0][1]:5d}")
        print(f"         Drowsy    {cm[1][0]:5d}   {cm[1][1]:5d}")
        
        print(f"\nğŸ“ˆ è©³ç´°ãªåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:")
        for class_name in target_names:
            print(f"\n{class_name}:")
            print(f"  é©åˆç‡ (Precision): {report[class_name]['precision']:.3f}")
            print(f"  å†ç¾ç‡ (Recall):    {report[class_name]['recall']:.3f}")
            print(f"  F1ã‚¹ã‚³ã‚¢:          {report[class_name]['f1-score']:.3f}")
            print(f"  ã‚µãƒãƒ¼ãƒˆ:          {report[class_name]['support']}")
        
        print(f"\nãƒã‚¯ãƒ­å¹³å‡:")
        print(f"  é©åˆç‡: {report['macro avg']['precision']:.3f}")
        print(f"  å†ç¾ç‡: {report['macro avg']['recall']:.3f}")
        print(f"  F1ã‚¹ã‚³ã‚¢: {report['macro avg']['f1-score']:.3f}")
        
        return {
            'accuracy': accuracy,
            'confusion_matrix': cm.tolist(),
            'classification_report': report
        }
    
    def plot_confusion_matrix(self, results: Dict):
        """æ··åŒè¡Œåˆ—ã‚’å¯è¦–åŒ–"""
        if not HAS_MATPLOTLIB:
            return
        
        print("\nğŸ“Š æ··åŒè¡Œåˆ—ã®å¯è¦–åŒ–")
        
        cm = np.array(results['confusion_matrix'])
        
        fig, ax = plt.subplots(figsize=(8, 6))
        im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
        ax.figure.colorbar(im, ax=ax)
        
        classes = ['Normal', 'Drowsy']
        ax.set(xticks=np.arange(cm.shape[1]),
               yticks=np.arange(cm.shape[0]),
               xticklabels=classes, yticklabels=classes,
               title='Confusion Matrix (Session-based Split)',
               ylabel='True label',
               xlabel='Predicted label')
        
        # æ•°å€¤ã‚’è¡¨ç¤º
        thresh = cm.max() / 2.
        for i in range(cm.shape[0]):
            for j in range(cm.shape[1]):
                ax.text(j, i, format(cm[i, j], 'd'),
                       ha="center", va="center",
                       color="white" if cm[i, j] > thresh else "black")
        
        plt.tight_layout()
        
        cm_path = os.path.join(
            self.output_dir, 'logs', f"{self.model_name}_confusion_matrix.png"
        )
        plt.savefig(cm_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… æ··åŒè¡Œåˆ—ã‚°ãƒ©ãƒ•ä¿å­˜: {cm_path}")
    
    def save_model(self, results: Optional[Dict] = None):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        print("\n" + "=" * 70)
        print("ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜")
        print("=" * 70)
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        model_path = os.path.join(self.output_dir, f"{self.model_name}.pth")
        self.estimator.save_model(model_path)
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {model_path}")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        metadata = {
            'model_name': self.model_name,
            'timestamp': datetime.now().isoformat(),
            'training_time': getattr(self, 'training_time', 0),
            'best_val_acc': max(self.estimator.history['val_acc']),
            'config': self.config,
            'split_method': 'session-based',
            'train_sessions': [s['name'] for s in self.data_manager.train_sessions],
            'val_sessions': [s['name'] for s in self.data_manager.val_sessions],
            'test_sessions': [s['name'] for s in self.data_manager.test_sessions],
            'data_statistics': {
                'train_count': len(self.data_manager.train_sequences),
                'val_count': len(self.data_manager.val_sequences),
                'test_count': len(self.data_manager.test_sequences)
            }
        }
        
        if results:
            metadata['test_accuracy'] = results['accuracy']
            metadata['confusion_matrix'] = results['confusion_matrix']
            metadata['classification_report'] = results['classification_report']
        
        metadata_path = os.path.join(self.output_dir, f"{self.model_name}_metadata.json")
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {metadata_path}")
    
    def run_full_training_pipeline(self, data_dir: str) -> bool:
        """
        å®Œå…¨ãªè¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ
        
        Args:
            data_dir (str): ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            bool: æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        print("\n" + "=" * 70)
        print("ğŸ“ å®Œå…¨è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½åˆ†å‰²ï¼‰")
        print("=" * 70)
        
        # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        if not self.load_data(data_dir):
            return False
        
        # 2. ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        self.create_model()
        
        # 3. ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        if not self.train_model():
            return False
        
        # 4. è¨“ç·´å±¥æ­´å¯è¦–åŒ–
        self.plot_training_history()
        
        # 5. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
        results = self.evaluate_model()
        
        # 6. æ··åŒè¡Œåˆ—å¯è¦–åŒ–
        if results is not None:
            self.plot_confusion_matrix(results)
        
        # 7. ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        self.save_model(results)
        
        print("\n" + "=" * 70)
        print("âœ… è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†")
        print("=" * 70)
        if results:
            print(f"ğŸ¯ æœ€çµ‚ãƒ†ã‚¹ãƒˆç²¾åº¦: {results['accuracy']:.2f}%")
        print(f"ğŸ“ ãƒ¢ãƒ‡ãƒ«: {self.output_dir}/{self.model_name}.pth")
        print("=" * 70)
        
        return True


def create_default_config() -> Dict:
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½œæˆ"""
    return {
        # ãƒ‡ãƒ¼ã‚¿è¨­å®š
        'train_ratio': 0.7,
        'val_ratio': 0.15,
        'test_ratio': 0.15,
        'normalization': 'zscore',
        
        # ãƒ¢ãƒ‡ãƒ«è¨­å®š
        'input_size': 12,
        'hidden_size1': 64,
        'hidden_size2': 32,
        'fc_size': 32,
        'num_classes': 2,
        'dropout_rate': 0.3,
        
        # è¨“ç·´è¨­å®š
        'epochs': 100,
        'batch_size': 32,
        'learning_rate': 0.001,
        'patience': 10,
        
        # å‡ºåŠ›è¨­å®š
        'output_dir': 'trained_models',
        'show_plots': False,
        'device': None
    }


def parse_args():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’ãƒ‘ãƒ¼ã‚¹"""
    parser = argparse.ArgumentParser(
        description='çœ æ°—æ¨å®šLSTMãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½åˆ†å‰²å¯¾å¿œç‰ˆï¼‰',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    # ãƒ‡ãƒ¼ã‚¿è¨­å®š
    parser.add_argument('--data-dir', type=str, default='data',
                       help='ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--output-dir', type=str, default='trained_models',
                       help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    
    # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    parser.add_argument('--input-size', type=int, default=12,
                       help='å…¥åŠ›æ¬¡å…ƒ')
    parser.add_argument('--hidden-size1', type=int, default=64,
                       help='LSTMç¬¬1å±¤ã®ãƒ¦ãƒ‹ãƒƒãƒˆæ•°')
    parser.add_argument('--hidden-size2', type=int, default=32,
                       help='LSTMç¬¬2å±¤ã®ãƒ¦ãƒ‹ãƒƒãƒˆæ•°')
    parser.add_argument('--fc-size', type=int, default=32,
                       help='å…¨çµåˆå±¤ã®ãƒ¦ãƒ‹ãƒƒãƒˆæ•°')
    parser.add_argument('--dropout', type=float, default=0.3,
                       help='ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡')
    
    # è¨“ç·´è¨­å®š
    parser.add_argument('--epochs', type=int, default=100,
                       help='ã‚¨ãƒãƒƒã‚¯æ•°')
    parser.add_argument('--batch-size', type=int, default=32,
                       help='ãƒãƒƒãƒã‚µã‚¤ã‚º')
    parser.add_argument('--lr', type=float, default=0.001,
                       help='å­¦ç¿’ç‡')
    parser.add_argument('--patience', type=int, default=10,
                       help='Early Stoppingã®å¿è€å€¤')
    
    # ãã®ä»–
    parser.add_argument('--device', type=str, default=None,
                       help='ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹ (cuda/cpu)')
    parser.add_argument('--show-plots', action='store_true',
                       help='ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º')
    
    return parser.parse_args()


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    args = parse_args()
    
    # è¨­å®šä½œæˆ
    config = create_default_config()
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ä¸Šæ›¸ã
    config['output_dir'] = args.output_dir
    config['input_size'] = args.input_size
    config['hidden_size1'] = args.hidden_size1
    config['hidden_size2'] = args.hidden_size2
    config['fc_size'] = args.fc_size
    config['dropout_rate'] = args.dropout
    config['epochs'] = args.epochs
    config['batch_size'] = args.batch_size
    config['learning_rate'] = args.lr
    config['patience'] = args.patience
    config['device'] = args.device
    config['show_plots'] = args.show_plots
    
    print("=" * 70)
    print("ğŸ“ çœ æ°—æ¨å®šãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚·ã‚¹ãƒ†ãƒ ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½åˆ†å‰²å¯¾å¿œç‰ˆï¼‰")
    print("=" * 70)
    print("\nğŸ“‹ è¨“ç·´è¨­å®š:")
    print(json.dumps(config, indent=2))
    
    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ä½œæˆ
    trainer = ModelTrainerSessionBased(config)
    
    # è¨“ç·´å®Ÿè¡Œ
    success = trainer.run_full_training_pipeline(args.data_dir)
    
    if success:
        print("\nğŸ‰ è¨“ç·´ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
    else:
        print("\nâŒ è¨“ç·´ã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)


if __name__ == "__main__":
    main()
