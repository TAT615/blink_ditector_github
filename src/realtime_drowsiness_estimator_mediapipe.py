"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¨å®šã‚·ã‚¹ãƒ†ãƒ ï¼ˆMediaPipeç‰ˆ - 12æ¬¡å…ƒç‰¹å¾´é‡å¯¾å¿œï¼‰
Real-time Drowsiness Estimation System with MediaPipe - 12D Features

è¨“ç·´æ¸ˆã¿LSTMãƒ¢ãƒ‡ãƒ«ï¼ˆ12æ¬¡å…ƒï¼‰ã‚’ä½¿ç”¨ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§çœ æ°—ã‚’æ¨å®šã—ã¾ã™ã€‚

ä½¿ã„æ–¹:
    python realtime_drowsiness_estimator_mediapipe_12d.py \
        --model-path trained_models/drowsiness_lstm_20251115_224046.pth
"""

import os
import sys
import cv2
import numpy as np
import time
import json
from datetime import datetime
from collections import deque
from typing import Dict, Optional, Tuple
import argparse
import mediapipe as mp

# PyTorchã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import torch
    import torch.nn as nn
except ImportError as e:
    print(f"âŒ PyTorchã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    print("   pip install torch ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„")
    sys.exit(1)


class EARCalculator:
    """Eye Aspect Ratioï¼ˆEARï¼‰è¨ˆç®—ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def calculate(eye_landmarks):
        """
        EARã‚’è¨ˆç®—
        
        Args:
            eye_landmarks: ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯6ç‚¹ [(x,y), ...]
            
        Returns:
            float: EARå€¤
        """
        if len(eye_landmarks) != 6:
            return 0.0
        
        # å‚ç›´è·é›¢
        v1 = np.linalg.norm(np.array(eye_landmarks[1]) - np.array(eye_landmarks[5]))
        v2 = np.linalg.norm(np.array(eye_landmarks[2]) - np.array(eye_landmarks[4]))
        
        # æ°´å¹³è·é›¢
        h = np.linalg.norm(np.array(eye_landmarks[0]) - np.array(eye_landmarks[3]))
        
        if h == 0:
            return 0.0
        
        # EARè¨ˆç®—
        ear = (v1 + v2) / (2.0 * h)
        return ear


class TwoCircleFitter:
    """2å††ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚¯ãƒ©ã‚¹ï¼ˆä¸Šã¾ã¶ãŸãƒ»ä¸‹ã¾ã¶ãŸï¼‰"""
    
    @staticmethod
    def fit_circle(points):
        """
        3ç‚¹ã‹ã‚‰å††ã‚’ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
        
        Args:
            points: [(x, y), (x, y), (x, y)]
            
        Returns:
            tuple: (center_x, center_y, radius) ã¾ãŸã¯ None
        """
        if len(points) != 3:
            return None
        
        try:
            points = np.array(points, dtype=np.float32)
            
            # è¡Œåˆ—Aã¨ãƒ™ã‚¯ãƒˆãƒ«bã‚’æ§‹ç¯‰
            A = np.zeros((3, 3))
            b = np.zeros(3)
            
            for i in range(3):
                x, y = points[i]
                A[i] = [2*x, 2*y, 1]
                b[i] = x*x + y*y
            
            # é€£ç«‹æ–¹ç¨‹å¼ã‚’è§£ã
            params = np.linalg.solve(A, b)
            
            center_x = params[0]
            center_y = params[1]
            radius = np.sqrt(params[2] + center_x**2 + center_y**2)
            
            return center_x, center_y, radius
            
        except:
            return None
    
    @staticmethod
    def fit_eyelids(eye_landmarks):
        """
        ä¸Šã¾ã¶ãŸãƒ»ä¸‹ã¾ã¶ãŸã®å††ã‚’ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
        
        Args:
            eye_landmarks: ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯6ç‚¹
                          [P1(ç›®é ­), P2(ä¸Š), P3(ä¸Š), P4(ç›®å°»), P5(ä¸‹), P6(ä¸‹)]
            
        Returns:
            tuple: ((c1_x, c1_y, c1_r), (c2_x, c2_y, c2_r)) ã¾ãŸã¯ (None, None)
        """
        if len(eye_landmarks) < 6:
            return None, None
        
        # ä¸Šã¾ã¶ãŸ3ç‚¹: P1(ç›®é ­), P2(ä¸Š), P3(ä¸Š)
        upper_points = [eye_landmarks[0], eye_landmarks[1], eye_landmarks[2]]
        c1 = TwoCircleFitter.fit_circle(upper_points)
        
        # ä¸‹ã¾ã¶ãŸ3ç‚¹: P1(ç›®é ­), P5(ä¸‹), P6(ä¸‹)
        lower_points = [eye_landmarks[0], eye_landmarks[4], eye_landmarks[5]]
        c2 = TwoCircleFitter.fit_circle(lower_points)
        
        return c1, c2


class DrowsinessLSTM(nn.Module):
    """çœ æ°—æ¨å®šç”¨LSTMãƒ¢ãƒ‡ãƒ«ï¼ˆ12æ¬¡å…ƒå¯¾å¿œï¼‰"""
    
    def __init__(self, input_size=12, hidden_size1=64, hidden_size2=32, 
                 fc_size=32, num_classes=2, dropout_rate=0.3):
        super(DrowsinessLSTM, self).__init__()
        
        self.hidden_size1 = hidden_size1
        self.hidden_size2 = hidden_size2
        
        # LSTMå±¤
        self.lstm1 = nn.LSTM(input_size, hidden_size1, batch_first=True)
        self.dropout1 = nn.Dropout(dropout_rate)
        
        self.lstm2 = nn.LSTM(hidden_size1, hidden_size2, batch_first=True)
        self.dropout2 = nn.Dropout(dropout_rate)
        
        # å…¨çµåˆå±¤
        self.fc1 = nn.Linear(hidden_size2, fc_size)
        self.relu = nn.ReLU()
        self.dropout3 = nn.Dropout(dropout_rate)
        
        self.fc2 = nn.Linear(fc_size, num_classes)
    
    def forward(self, x):
        # x: (batch, sequence_length, input_size)
        
        # LSTMå±¤1
        lstm1_out, _ = self.lstm1(x)
        lstm1_out = self.dropout1(lstm1_out)
        
        # LSTMå±¤2
        lstm2_out, _ = self.lstm2(lstm1_out)
        lstm2_out = self.dropout2(lstm2_out)
        
        # æœ€å¾Œã®æ™‚åˆ»ã®å‡ºåŠ›ã‚’ä½¿ç”¨
        last_output = lstm2_out[:, -1, :]
        
        # å…¨çµåˆå±¤
        fc1_out = self.fc1(last_output)
        fc1_out = self.relu(fc1_out)
        fc1_out = self.dropout3(fc1_out)
        
        output = self.fc2(fc1_out)
        
        return output


class RealtimeDrowsinessDetector:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ï¼ˆ12æ¬¡å…ƒç‰¹å¾´é‡å¯¾å¿œï¼‰"""
    
    # MediaPipe Face Meshã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    LEFT_EYE_INDICES = [33, 160, 158, 133, 153, 144]
    RIGHT_EYE_INDICES = [362, 385, 387, 263, 373, 380]
    
    # ç¬ãçŠ¶æ…‹
    STATE_OPEN = 0
    STATE_CLOSING = 1
    STATE_CLOSED = 2
    STATE_OPENING = 3
    
    def __init__(self, model_path, sequence_length=10, ear_threshold=0.21):
        """
        åˆæœŸåŒ–
        
        Args:
            model_path (str): å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
            sequence_length (int): LSTMã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·
            ear_threshold (float): EARé–¾å€¤
        """
        self.sequence_length = sequence_length
        self.ear_threshold = ear_threshold
        
        # MediaPipe Face Mesh
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        
        # ç¬ãæ¤œå‡ºç”¨
        self.blink_state = self.STATE_OPEN
        self.state_start_time = time.time()
        self.t1 = 0  # OPEN â†’ CLOSING
        self.t2 = 0  # CLOSING â†’ CLOSED
        self.t3 = 0  # CLOSED â†’ OPENING
        
        # å‰å›ã®ç¬ãæ™‚åˆ»ï¼ˆé–“éš”è¨ˆç®—ç”¨ï¼‰
        self.last_blink_time = None
        
        # ç‰¹å¾´é‡ãƒãƒƒãƒ•ã‚¡ï¼ˆ12æ¬¡å…ƒ Ã— sequence_lengthï¼‰
        self.feature_buffer = deque(maxlen=sequence_length)
        
        # LSTMãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        print("ğŸ§  ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        checkpoint = torch.load(model_path, map_location=self.device)
        model_params = checkpoint.get('model_params', {})
        
        self.model = DrowsinessLSTM(
            input_size=model_params.get('input_size', 12),
            hidden_size1=model_params.get('hidden_size1', 64),
            hidden_size2=model_params.get('hidden_size2', 32),
            fc_size=model_params.get('fc_size', 32),
            num_classes=model_params.get('num_classes', 2),
            dropout_rate=model_params.get('dropout_rate', 0.3)
        )
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        print(f"   ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
        print(f"   å…¥åŠ›æ¬¡å…ƒ: {model_params.get('input_size', 12)}")
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {model_path}")
        
        # æ¨å®šçµæœ
        self.current_prediction = None
        self.current_probability = None
        
        # çµ±è¨ˆ
        self.total_blinks = 0
        self.drowsy_count = 0
        
        print("=" * 70)
        print("ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•")
        print("=" * 70)
        print(f"ğŸ“ ãƒ¢ãƒ‡ãƒ«: {model_path}")
        print(f"ğŸ“Š ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·: {sequence_length}")
        print(f"ğŸ‘ï¸  EARé–¾å€¤: {ear_threshold}")
        print(f"ğŸ”¢ ç‰¹å¾´é‡æ¬¡å…ƒ: 12æ¬¡å…ƒï¼ˆ2å††æ–¹å¼ï¼‰")
        print("=" * 70)
    
    def detect_blink(self, ear, left_eye_landmarks, right_eye_landmarks):
        """
        ç¬ãã‚’æ¤œå‡ºã—ã€å®Œäº†æ™‚ã«12æ¬¡å…ƒç‰¹å¾´é‡ã‚’æŠ½å‡º
        
        Args:
            ear (float): Eye Aspect Ratio
            left_eye_landmarks (list): å·¦ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            right_eye_landmarks (list): å³ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            
        Returns:
            np.array: 12æ¬¡å…ƒç‰¹å¾´é‡ ã¾ãŸã¯ None
        """
        current_time = time.time()
        
        # çŠ¶æ…‹é·ç§»
        if self.blink_state == self.STATE_OPEN:
            if ear < self.ear_threshold:
                # OPEN â†’ CLOSING
                self.blink_state = self.STATE_CLOSING
                self.t1 = current_time
                
        elif self.blink_state == self.STATE_CLOSING:
            if ear < self.ear_threshold * 0.8:
                # CLOSING â†’ CLOSED
                self.blink_state = self.STATE_CLOSED
                self.t2 = current_time
                
        elif self.blink_state == self.STATE_CLOSED:
            if ear > self.ear_threshold:
                # CLOSED â†’ OPENING
                self.blink_state = self.STATE_OPENING
                self.t3 = current_time
                
        elif self.blink_state == self.STATE_OPENING:
            if ear > self.ear_threshold * 1.2:
                # OPENING â†’ OPEN (ç¬ãå®Œäº†)
                self.blink_state = self.STATE_OPEN
                
                # 12æ¬¡å…ƒç‰¹å¾´é‡ã‚’æŠ½å‡º
                features = self.extract_blink_features(
                    left_eye_landmarks, 
                    right_eye_landmarks
                )
                
                if features is not None:
                    self.total_blinks += 1
                    self.last_blink_time = current_time
                    return features
        
        return None
    
    def extract_blink_features(self, left_eye_landmarks, right_eye_landmarks):
        """
        ç¬ãå®Œäº†æ™‚ã«12æ¬¡å…ƒç‰¹å¾´é‡ã‚’æŠ½å‡º
        
        12æ¬¡å…ƒã®å†…è¨³:
        1. closing_time (é–‰çœ¼æ™‚é–“)
        2. opening_time (é–‹çœ¼æ™‚é–“)
        3. blink_coefficient (ç¬ãä¿‚æ•° To/Tc)
        4. timestamp (ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—)
        5. total_duration (ç·ç¬ãæ™‚é–“)
        6. interval (ç¬ãé–“éš”)
        7. c1_center_x (ä¸Šã¾ã¶ãŸå††ã®ä¸­å¿ƒX)
        8. c1_center_y (ä¸Šã¾ã¶ãŸå††ã®ä¸­å¿ƒY)
        9. c1_radius (ä¸Šã¾ã¶ãŸå††ã®åŠå¾„)
        10. c2_center_x (ä¸‹ã¾ã¶ãŸå††ã®ä¸­å¿ƒX)
        11. c2_center_y (ä¸‹ã¾ã¶ãŸå††ã®ä¸­å¿ƒY)
        12. c2_radius (ä¸‹ã¾ã¶ãŸå††ã®åŠå¾„)
        
        Returns:
            np.array: 12æ¬¡å…ƒç‰¹å¾´é‡ ã¾ãŸã¯ None
        """
        try:
            current_time = time.time()
            
            # æ™‚é–“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨ˆç®—
            closing_time = self.t2 - self.t1
            opening_time = self.t3 - self.t2
            total_duration = closing_time + opening_time
            blink_coefficient = opening_time / closing_time if closing_time > 0 else 0
            
            # æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
            if not (0.025 <= closing_time <= 1.0):
                return None
            if not (0.05 <= opening_time <= 0.6):
                return None
            if not (0.5 <= blink_coefficient <= 8.0):
                return None
            
            # ç¬ãé–“éš”ã®è¨ˆç®—
            if self.last_blink_time is not None:
                interval = current_time - self.last_blink_time
            else:
                interval = 0.0
            
            # 2å††ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            c1_left, c2_left = TwoCircleFitter.fit_eyelids(left_eye_landmarks)
            c1_right, c2_right = TwoCircleFitter.fit_eyelids(right_eye_landmarks)
            
            # ä¸¡ç›®ã®å¹³å‡ã‚’å–ã‚‹
            if c1_left and c1_right and c2_left and c2_right:
                c1_center_x = (c1_left[0] + c1_right[0]) / 2.0
                c1_center_y = (c1_left[1] + c1_right[1]) / 2.0
                c1_radius = (c1_left[2] + c1_right[2]) / 2.0
                c2_center_x = (c2_left[0] + c2_right[0]) / 2.0
                c2_center_y = (c2_left[1] + c2_right[1]) / 2.0
                c2_radius = (c2_left[2] + c2_right[2]) / 2.0
            else:
                # 2å††ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å¤±æ•—æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                c1_center_x = c1_center_y = c1_radius = 0.0
                c2_center_x = c2_center_y = c2_radius = 0.0
            
            # 12æ¬¡å…ƒç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«
            features = np.array([
                closing_time,
                opening_time,
                blink_coefficient,
                self.t1,           # timestamp
                total_duration,
                interval,
                c1_center_x,
                c1_center_y,
                c1_radius,
                c2_center_x,
                c2_center_y,
                c2_radius
            ], dtype=np.float32)
            
            return features
            
        except Exception as e:
            print(f"âš ï¸  ç‰¹å¾´é‡æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def predict_drowsiness(self):
        """
        LSTMãƒ¢ãƒ‡ãƒ«ã§çœ æ°—ã‚’æ¨å®š
        
        Returns:
            tuple: (äºˆæ¸¬ã‚¯ãƒ©ã‚¹, çœ æ°—ç¢ºç‡) ã¾ãŸã¯ (None, None)
        """
        if len(self.feature_buffer) < self.sequence_length:
            return None, None
        
        try:
            # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ä½œæˆ
            sequence = np.array(list(self.feature_buffer))
            sequence = sequence.reshape(1, self.sequence_length, 12)
            
            # ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
            sequence_tensor = torch.FloatTensor(sequence).to(self.device)
            
            # æ¨è«–
            with torch.no_grad():
                output = self.model(sequence_tensor)
                probabilities = torch.softmax(output, dim=1)
                predicted_class = torch.argmax(probabilities, dim=1).item()
                drowsy_prob = probabilities[0, 1].item()
            
            self.current_prediction = predicted_class
            self.current_probability = drowsy_prob
            
            if predicted_class == 1:
                self.drowsy_count += 1
            
            return predicted_class, drowsy_prob
            
        except Exception as e:
            print(f"âš ï¸  æ¨è«–ã‚¨ãƒ©ãƒ¼: {e}")
            return None, None
    
    def process_frame(self, frame):
        """
        ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†
        
        Args:
            frame: OpenCVã®ãƒ•ãƒ¬ãƒ¼ãƒ  (BGR)
            
        Returns:
            tuple: (å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ , EARå€¤, äºˆæ¸¬ã‚¯ãƒ©ã‚¹, çœ æ°—ç¢ºç‡)
        """
        # RGBå¤‰æ›
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # MediaPipeã§é¡”æ¤œå‡º
        results = self.face_mesh.process(rgb_frame)
        
        if not results.multi_face_landmarks:
            return frame, None, None, None
        
        face_landmarks = results.multi_face_landmarks[0]
        h, w = frame.shape[:2]
        
        # ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’å–å¾—
        left_eye = [(int(face_landmarks.landmark[i].x * w),
                     int(face_landmarks.landmark[i].y * h))
                    for i in self.LEFT_EYE_INDICES]
        
        right_eye = [(int(face_landmarks.landmark[i].x * w),
                      int(face_landmarks.landmark[i].y * h))
                     for i in self.RIGHT_EYE_INDICES]
        
        # EARè¨ˆç®—
        left_ear = EARCalculator.calculate(left_eye)
        right_ear = EARCalculator.calculate(right_eye)
        avg_ear = (left_ear + right_ear) / 2.0
        
        # ç¬ãæ¤œå‡º
        blink_features = self.detect_blink(avg_ear, left_eye, right_eye)
        
        # ç‰¹å¾´é‡ã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
        if blink_features is not None:
            self.feature_buffer.append(blink_features)
        
        # çœ æ°—æ¨å®š
        pred_class, drowsy_prob = self.predict_drowsiness()
        
        # ç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æç”»
        for point in left_eye + right_eye:
            cv2.circle(frame, point, 1, (0, 255, 0), -1)
        
        # æƒ…å ±è¡¨ç¤º
        cv2.putText(frame, f"EAR: {avg_ear:.3f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.putText(frame, f"Blinks: {self.total_blinks}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.putText(frame, f"Buffer: {len(self.feature_buffer)}/{self.sequence_length}", 
                    (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        if pred_class is not None:
            status = "DROWSY" if pred_class == 1 else "NORMAL"
            color = (0, 0, 255) if pred_class == 1 else (0, 255, 0)
            
            cv2.putText(frame, f"Status: {status}", (10, 120),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            
            cv2.putText(frame, f"Drowsy Prob: {drowsy_prob:.2%}", (10, 150),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        
        return frame, avg_ear, pred_class, drowsy_prob
    
    def run(self, camera_id=0):
        """
        ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨å®šã‚’å®Ÿè¡Œ
        
        Args:
            camera_id (int): ã‚«ãƒ¡ãƒ©ID
        """
        cap = cv2.VideoCapture(camera_id)
        
        if not cap.isOpened():
            print("âŒ ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        print("\nğŸ¥ ã‚«ãƒ¡ãƒ©èµ·å‹•")
        print("   'q' ã‚­ãƒ¼ã§çµ‚äº†")
        print("=" * 70)
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
                processed_frame, ear, pred_class, drowsy_prob = self.process_frame(frame)
                
                # è¡¨ç¤º
                cv2.imshow('Drowsiness Detection (12D Features)', processed_frame)
                
                # ã‚­ãƒ¼å…¥åŠ›å¾…ã¡
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
        
        finally:
            cap.release()
            cv2.destroyAllWindows()
            
            # çµ±è¨ˆè¡¨ç¤º
            print("\n" + "=" * 70)
            print("ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ")
            print("=" * 70)
            print(f"ç·ç¬ãæ•°: {self.total_blinks}")
            print(f"çœ æ°—æ¤œå‡ºå›æ•°: {self.drowsy_count}")
            print("=" * 70)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¨å®šã‚·ã‚¹ãƒ†ãƒ  (12æ¬¡å…ƒç‰¹å¾´é‡å¯¾å¿œ)')
    parser.add_argument('--model-path', type=str, required=True,
                        help='å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--sequence-length', type=int, default=10,
                        help='LSTMã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·')
    parser.add_argument('--ear-threshold', type=float, default=0.21,
                        help='EARé–¾å€¤')
    parser.add_argument('--camera-id', type=int, default=0,
                        help='ã‚«ãƒ¡ãƒ©ID')
    
    args = parser.parse_args()
    
    # æ¤œå‡ºå™¨ã‚’åˆæœŸåŒ–
    detector = RealtimeDrowsinessDetector(
        model_path=args.model_path,
        sequence_length=args.sequence_length,
        ear_threshold=args.ear_threshold
    )
    
    # å®Ÿè¡Œ
    detector.run(camera_id=args.camera_id)


if __name__ == "__main__":
    main()