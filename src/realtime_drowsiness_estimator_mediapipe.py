"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¨å®šã‚·ã‚¹ãƒ†ãƒ ï¼ˆMediaPipeç‰ˆï¼‰- ä¿®æ­£ç‰ˆ
Real-time Drowsiness Estimation System with MediaPipe - FIXED

è¨“ç·´æ¸ˆã¿LSTMãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§çœ æ°—ã‚’æ¨å®šã—ã¾ã™ã€‚
"""

import os
import sys
import cv2
import numpy as np
import time
import json
from datetime import datetime
from collections import deque
from typing import Dict, Optional, Tuple
import argparse

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from src.blink_feature_extractor import BlinkFeatureExtractor
    from src.lstm_drowsiness_model import DrowsinessEstimator
except ImportError:
    try:
        from blink_feature_extractor import BlinkFeatureExtractor
        from lstm_drowsiness_model import DrowsinessEstimator
    except ImportError as e:
        print(f"âŒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print("   å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«: blink_feature_extractor.py, lstm_drowsiness_model.py")
        sys.exit(1)

# MediaPipeç‰ˆç¬ãæ¤œå‡ºå™¨ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from blink_detector_mediapipe import BlinkDetectorMediaPipe
except ImportError:
    try:
        from src.blink_detector_mediapipe import BlinkDetectorMediaPipe
    except ImportError as e:
        print(f"âŒ MediaPipeç‰ˆç¬ãæ¤œå‡ºå™¨ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print("   blink_detector_mediapipe.py ãŒå¿…è¦ã§ã™")
        sys.exit(1)


class RealtimeDrowsinessEstimatorMediaPipe:
    """
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¨å®šã‚·ã‚¹ãƒ†ãƒ ï¼ˆMediaPipeç‰ˆï¼‰
    
    æ©Ÿèƒ½:
    - MediaPipe Face Meshã«ã‚ˆã‚‹é«˜ç²¾åº¦ç¬ãæ¤œå‡º
    - ç‰¹å¾´é‡æŠ½å‡ºã¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”Ÿæˆ
    - LSTMæ¨è«–ã«ã‚ˆã‚‹çœ æ°—æ¨å®š
    - ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½
    - çµ±è¨ˆè¨˜éŒ²
    """
    
    # çŠ¶æ…‹å®šç¾©
    STATE_NORMAL = 0
    STATE_DROWSY = 1
    STATE_UNKNOWN = -1
    
    def __init__(self, model_path: str, normalization_params_path: Optional[str] = None,
                 sequence_length: int = 10, alert_threshold: float = 0.7):
        """
        åˆæœŸåŒ–
        
        Args:
            model_path (str): è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
            normalization_params_path (str): æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹
            sequence_length (int): ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·
            alert_threshold (float): ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ç™ºã™ã‚‹çœ æ°—ç¢ºç‡ã®é–¾å€¤
        """
        self.model_path = model_path
        self.normalization_params_path = normalization_params_path
        self.sequence_length = sequence_length
        self.alert_threshold = alert_threshold
        
        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆæœŸåŒ–
        print("=" * 70)
        print("ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¨å®šã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ– (MediaPipeç‰ˆ)")
        print("=" * 70)
        
        # MediaPipeç‰ˆç¬ãæ¤œå‡ºå™¨
        print("\nğŸ“¹ MediaPipe Face MeshåˆæœŸåŒ–...")
        self.blink_detector = BlinkDetectorMediaPipe(
            buffer_size=300,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        print("   âœ… 478ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯é«˜ç²¾åº¦é¡”æ¤œå‡º")
        
        # ç‰¹å¾´é‡æŠ½å‡ºå™¨
        print("ğŸ”§ ç‰¹å¾´é‡æŠ½å‡ºå™¨åˆæœŸåŒ–...")
        self.feature_extractor = BlinkFeatureExtractor(sequence_length=sequence_length)
        
        # æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        if normalization_params_path and os.path.exists(normalization_params_path):
            self.feature_extractor.load_normalization_params(normalization_params_path)
            print(f"   âœ… æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {normalization_params_path}")
        else:
            print("   âš ï¸ æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãªã—ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§æ­£è¦åŒ–ã—ã¦ãã ã•ã„ï¼‰")
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        print("ğŸ§  LSTMãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿...")
        self.estimator = DrowsinessEstimator()
        self.estimator.load_model(model_path)
        print(f"   âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: {model_path}")
        
        # ã‚«ãƒ¡ãƒ©è¨­å®š
        self.camera = None
        self.camera_width = 640
        self.camera_height = 480
        self.fps = 30
        
        # æ¨å®šçµæœã®å±¥æ­´
        self.prediction_history = deque(maxlen=100)
        self.drowsy_probability_history = deque(maxlen=100)
        
        # ç¾åœ¨ã®çŠ¶æ…‹
        self.current_state = self.STATE_UNKNOWN
        self.current_probability = 0.0
        self.last_prediction_time = None
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
        self.alert_active = False
        self.alert_start_time = None
        self.consecutive_drowsy_count = 0
        self.alert_cooldown = 5.0  # ã‚¢ãƒ©ãƒ¼ãƒˆå¾Œã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æ™‚é–“ï¼ˆç§’ï¼‰
        
        # çµ±è¨ˆ
        self.stats = {
            'total_predictions': 0,
            'drowsy_predictions': 0,
            'normal_predictions': 0,
            'total_alerts': 0,
            'session_start_time': time.time()
        }
        
        # UIè¨­å®š
        self.window_name = "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¨å®š (MediaPipeç‰ˆ)"
        
        print("\n" + "=" * 70)
        print("âœ… åˆæœŸåŒ–å®Œäº†")
        print("=" * 70)
    
    def initialize_camera(self, camera_id=0):
        """
        ã‚«ãƒ¡ãƒ©ã‚’åˆæœŸåŒ–
        
        Args:
            camera_id (int): ã‚«ãƒ¡ãƒ©ID
            
        Returns:
            bool: æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        self.camera = cv2.VideoCapture(camera_id)
        
        if not self.camera.isOpened():
            print(f"âŒ ã‚«ãƒ¡ãƒ© {camera_id} ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")
            return False
        
        # ã‚«ãƒ¡ãƒ©è¨­å®š
        self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, self.camera_width)
        self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, self.camera_height)
        self.camera.set(cv2.CAP_PROP_FPS, self.fps)
        
        print(f"âœ… ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–æˆåŠŸ (ID: {camera_id})")
        print(f"   è§£åƒåº¦: {self.camera_width}x{self.camera_height}")
        print(f"   FPS: {self.fps}")
        
        return True
    
    def start_calibration(self):
        """ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹"""
        print("\n" + "=" * 70)
        print("ğŸ¯ ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")
        print("=" * 70)
        print("æ¬¡ã®5ç§’é–“ã€ãƒªãƒ©ãƒƒã‚¯ã‚¹ã—ã¦è‡ªç„¶ã«ç¬ãã—ã¦ãã ã•ã„")
        print()
        
        self.blink_detector.start_calibration()
    
    def process_frame(self, frame):
        """
        ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†
        
        Args:
            frame: ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ 
            
        Returns:
            tuple: (å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ , æ¨å®šçµæœ)
        """
        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å·¦å³åè»¢
        frame = cv2.flip(frame, 1)
        
        # MediaPipeã§ç¬ãæ¤œå‡º
        blink_info = self.blink_detector.detect_blink(frame)
        
        # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’å–å¾—ã—ã¦æç”»
        landmarks = self.blink_detector.detect_face_and_landmarks(frame)
        if landmarks is not None:
            frame = self.blink_detector.draw_landmarks(frame, landmarks)
        
        # æ¨å®šçµæœ
        prediction_result = None
        
        # ç¬ããŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆ
        if blink_info is not None:
            # ====== ä¿®æ­£ç®‡æ‰€: extract_featuresãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ ======
            # ç¬ããƒ‡ãƒ¼ã‚¿ã‚’é©åˆ‡ãªå½¢å¼ã«å¤‰æ›
            blink_data = {
                't1': blink_info.get('timestamp', 0) - blink_info.get('total_duration', 0),
                't2': blink_info.get('timestamp', 0) - blink_info.get('opening_time', 0),
                't3': blink_info.get('timestamp', 0),
                'ear_min': blink_info.get('min_ear', 0)
            }
            
            # extract_featuresãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
            features = self.feature_extractor.extract_features(blink_data)
            
            if features is not None:
                # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãŒæºœã¾ã£ãŸã‚‰æ¨å®šå®Ÿè¡Œ
                sequence = self.feature_extractor.get_sequence(normalize=True)
                
                if sequence is not None:
                    # LSTMæ¨è«–
                    pred_class = self.estimator.predict(sequence[np.newaxis, ...])[0]
                    pred_proba = self.estimator.predict_proba(sequence[np.newaxis, ...])[0]
                    
                    # çµæœã‚’è¨˜éŒ²
                    self.prediction_history.append(pred_class)
                    self.drowsy_probability_history.append(pred_proba[1])
                    
                    # çµ±è¨ˆæ›´æ–°
                    self.stats['total_predictions'] += 1
                    if pred_class == self.STATE_DROWSY:
                        self.stats['drowsy_predictions'] += 1
                        self.consecutive_drowsy_count += 1
                    else:
                        self.stats['normal_predictions'] += 1
                        self.consecutive_drowsy_count = 0
                    
                    # çŠ¶æ…‹æ›´æ–°
                    self.current_state = pred_class
                    self.current_probability = pred_proba[1]
                    self.last_prediction_time = time.time()
                    
                    # ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
                    self._check_alert()
                    
                    prediction_result = {
                        'class': pred_class,
                        'probability': pred_proba[1],
                        'state': 'DROWSY' if pred_class == self.STATE_DROWSY else 'NORMAL'
                    }
        
        return frame, prediction_result
    
    def _check_alert(self):
        """ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ãƒã‚§ãƒƒã‚¯"""
        current_time = time.time()
        
        # çœ æ°—ç¢ºç‡ãŒé–¾å€¤ã‚’è¶…ãˆã€ã‹ã¤é€£ç¶šæ¤œå‡ºã®å ´åˆ
        if (self.current_probability >= self.alert_threshold and 
            self.consecutive_drowsy_count >= 3):
            
            # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ä¸­ã§ãªã‘ã‚Œã°ã‚¢ãƒ©ãƒ¼ãƒˆç™ºå‹•
            if (self.alert_start_time is None or 
                current_time - self.alert_start_time >= self.alert_cooldown):
                
                self.alert_active = True
                self.alert_start_time = current_time
                self.stats['total_alerts'] += 1
                
                print(f"\nâš ï¸ ã€ã‚¢ãƒ©ãƒ¼ãƒˆã€‘çœ æ°—ã‚’æ¤œå‡ºã—ã¾ã—ãŸï¼ (ç¢ºç‡: {self.current_probability:.1%})")
                print(f"   ä¼‘æ†©ã‚’å–ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™\n")
        else:
            self.alert_active = False
    
    def draw_ui(self, frame):
        """
        UIã‚’æç”»
        
        Args:
            frame: ãƒ•ãƒ¬ãƒ¼ãƒ 
            
        Returns:
            frame: UIæç”»æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        """
        h, w = frame.shape[:2]
        
        # åŠé€æ˜ã®èƒŒæ™¯
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, 0), (w, 250), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.3, frame, 0.7, 0, frame)
        
        y_offset = 30
        line_height = 30
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        cv2.putText(frame, "Drowsiness Estimation (MediaPipe)", 
                   (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        y_offset += line_height
        
        # ç¾åœ¨ã®çŠ¶æ…‹
        if self.current_state == self.STATE_DROWSY:
            state_text = "DROWSY"
            state_color = (0, 0, 255)  # èµ¤
        elif self.current_state == self.STATE_NORMAL:
            state_text = "NORMAL"
            state_color = (0, 255, 0)  # ç·‘
        else:
            state_text = "UNKNOWN"
            state_color = (128, 128, 128)  # ã‚°ãƒ¬ãƒ¼
        
        cv2.putText(frame, f"State: {state_text}", 
                   (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, state_color, 2)
        y_offset += line_height
        
        # çœ æ°—ç¢ºç‡
        prob_text = f"Drowsy Prob: {self.current_probability:.1%}"
        prob_color = (0, 255, 0) if self.current_probability < 0.5 else (0, 0, 255)
        cv2.putText(frame, prob_text, 
                   (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, prob_color, 2)
        y_offset += line_height
        
        # ç¢ºç‡ãƒãƒ¼
        bar_width = 300
        bar_height = 20
        bar_x = 10
        bar_y = y_offset
        
        # èƒŒæ™¯
        cv2.rectangle(frame, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), 
                     (50, 50, 50), -1)
        
        # ç¢ºç‡ãƒãƒ¼
        prob_bar_width = int(bar_width * self.current_probability)
        bar_color = (0, 255, 0) if self.current_probability < 0.5 else (0, 0, 255)
        cv2.rectangle(frame, (bar_x, bar_y), (bar_x + prob_bar_width, bar_y + bar_height), 
                     bar_color, -1)
        
        # é–¾å€¤ãƒ©ã‚¤ãƒ³
        threshold_x = bar_x + int(bar_width * self.alert_threshold)
        cv2.line(frame, (threshold_x, bar_y), (threshold_x, bar_y + bar_height), 
                (255, 255, 255), 2)
        
        y_offset += bar_height + 15
        
        # æ¤œå‡ºå™¨ã®çµ±è¨ˆ
        detector_stats = self.blink_detector.get_statistics()
        
        # EARå€¤
        ear = detector_stats['current_ear']
        ear_color = (0, 255, 0)
        if self.blink_detector.ear_closed_threshold and ear <= self.blink_detector.ear_closed_threshold:
            ear_color = (0, 0, 255)
        
        cv2.putText(frame, f"EAR: {ear:.3f}", 
                   (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, ear_color, 2)
        y_offset += line_height
        
        # ç¬ãçµ±è¨ˆ
        cv2.putText(frame, f"Blinks: {detector_stats['total_blinks']}", 
                   (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        y_offset += line_height
        
        # æ¨å®šå›æ•°
        cv2.putText(frame, f"Predictions: {self.stats['total_predictions']}", 
                   (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        y_offset += line_height
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆå›æ•°
        cv2.putText(frame, f"Alerts: {self.stats['total_alerts']}", 
                   (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        y_offset += line_height
        
        # ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹
        if self.blink_detector.calibration_active:
            elapsed = time.time() - self.blink_detector.calibration_start_time
            remaining = self.blink_detector.calibration_duration - elapsed
            
            cv2.putText(frame, f"Calibrating: {remaining:.1f}s", 
                       (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        else:
            calib_text = "Calibrated: YES" if detector_stats['calibrated'] else "NOT Calibrated (Press C)"
            calib_color = (0, 255, 0) if detector_stats['calibrated'] else (0, 0, 255)
            cv2.putText(frame, calib_text, 
                       (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, calib_color, 2)
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆè¡¨ç¤º
        if self.alert_active:
            alert_text = "âš ï¸ DROWSINESS ALERT!"
            text_size = cv2.getTextSize(alert_text, cv2.FONT_HERSHEY_SIMPLEX, 1.5, 3)[0]
            alert_x = (w - text_size[0]) // 2
            alert_y = h - 100
            
            # ç‚¹æ»…åŠ¹æœ
            if int(time.time() * 3) % 2 == 0:
                cv2.putText(frame, alert_text, 
                           (alert_x, alert_y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
        
        return frame
    
    def run(self):
        """
        ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè¡Œ
        """
        # ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–
        if not self.initialize_camera():
            return
        
        print("\n" + "=" * 70)
        print("ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¨å®šã‚·ã‚¹ãƒ†ãƒ èµ·å‹•")
        print("=" * 70)
        print("æ“ä½œæ–¹æ³•:")
        print("  [C] - ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæœ€åˆã«å®Ÿè¡Œæ¨å¥¨ï¼‰")
        print("  [R] - çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ")
        print("  [ESC] - çµ‚äº†")
        print(f"ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤: {self.alert_threshold:.0%}")
        print("=" * 70)
        print("ğŸ‘‰ ã¾ãš[C]ã‚­ãƒ¼ã§ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        
        # FPSè¨ˆæ¸¬
        fps = 0
        fps_start_time = time.time()
        fps_frame_count = 0
        
        try:
            while True:
                ret, frame = self.camera.read()
                if not ret:
                    print("âŒ ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—å¤±æ•—")
                    break
                
                # FPSè¨ˆç®—
                fps_frame_count += 1
                if fps_frame_count >= 30:
                    fps_end_time = time.time()
                    fps = fps_frame_count / (fps_end_time - fps_start_time)
                    fps_start_time = fps_end_time
                    fps_frame_count = 0
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
                frame, prediction = self.process_frame(frame)
                
                # UIæç”»
                frame = self.draw_ui(frame)
                
                # FPSè¡¨ç¤º
                cv2.putText(frame, f"FPS: {fps:.1f}", 
                           (frame.shape[1] - 120, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                
                # è¡¨ç¤º
                cv2.imshow(self.window_name, frame)
                
                # ã‚­ãƒ¼å…¥åŠ›å‡¦ç†
                key = cv2.waitKey(1) & 0xFF
                
                if key == 27:  # ESC
                    break
                elif key == ord('c') or key == ord('C'):
                    self.start_calibration()
                elif key == ord('r') or key == ord('R'):
                    print("\nğŸ”„ çµ±è¨ˆã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
                    self.stats = {
                        'total_predictions': 0,
                        'drowsy_predictions': 0,
                        'normal_predictions': 0,
                        'total_alerts': 0,
                        'session_start_time': time.time()
                    }
        
        finally:
            # çµ‚äº†å‡¦ç†
            self.cleanup()
    
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾"""
        if self.camera:
            self.camera.release()
        
        cv2.destroyAllWindows()
        
        # æœ€çµ‚çµ±è¨ˆ
        session_duration = time.time() - self.stats['session_start_time']
        
        print("\n" + "=" * 70)
        print("ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ")
        print("=" * 70)
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“: {session_duration/60:.1f}åˆ†")
        print(f"ç·æ¨å®šå›æ•°: {self.stats['total_predictions']}")
        print(f"  - æ­£å¸¸: {self.stats['normal_predictions']}")
        print(f"  - çœ æ°—: {self.stats['drowsy_predictions']}")
        print(f"ç·ã‚¢ãƒ©ãƒ¼ãƒˆå›æ•°: {self.stats['total_alerts']}")
        
        if self.stats['total_predictions'] > 0:
            drowsy_rate = self.stats['drowsy_predictions'] / self.stats['total_predictions']
            print(f"çœ æ°—æ¤œå‡ºç‡: {drowsy_rate:.1%}")
        
        print("=" * 70)
        print()
        print("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¨å®šã‚·ã‚¹ãƒ†ãƒ ã‚’çµ‚äº†ã—ã¾ã—ãŸ")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description="ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çœ æ°—æ¨å®šã‚·ã‚¹ãƒ†ãƒ  (MediaPipeç‰ˆ)")
    parser.add_argument('--model', type=str, required=True,
                       help='è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--norm-params', type=str, default=None,
                       help='æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹')
    parser.add_argument('--sequence-length', type=int, default=10,
                       help='ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ï¼‰')
    parser.add_argument('--threshold', type=float, default=0.7,
                       help='ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.7ï¼‰')
    parser.add_argument('--camera', type=int, default=0,
                       help='ã‚«ãƒ¡ãƒ©IDï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0ï¼‰')
    
    args = parser.parse_args()
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    estimator = RealtimeDrowsinessEstimatorMediaPipe(
        model_path=args.model,
        normalization_params_path=args.norm_params,
        sequence_length=args.sequence_length,
        alert_threshold=args.threshold
    )
    
    # å®Ÿè¡Œ
    estimator.run()


if __name__ == "__main__":
    main()