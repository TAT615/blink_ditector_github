"""
çœ æ°—æ¨å®šãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Drowsiness Model Training Script

åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦LSTMãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¾ã™ã€‚
"""

import os
import sys
import argparse
import json
import time
from datetime import datetime
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, Optional

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from src.drowsiness_data_manager import DrowsinessDataManager
    from src.lstm_drowsiness_model import DrowsinessEstimator
except ImportError as e:
    print(f"âŒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    print("   å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«: src/drowsiness_data_manager.py, src/lstm_drowsiness_model.py")
    print("   ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„: python -m src.train_drowsiness_model")
    sys.exit(1)


class ModelTrainer:
    """
    ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, config: Dict):
        """
        åˆæœŸåŒ–
        
        Args:
            config (Dict): è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        """
        self.config = config
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        self.output_dir = config.get('output_dir', 'trained_models')
        self.log_dir = os.path.join(self.output_dir, 'logs')
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(self.log_dir, exist_ok=True)
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.model_name = f"drowsiness_lstm_{self.timestamp}"
        
        # ãƒ‡ãƒ¼ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        self.data_manager = None
        
        # ãƒ¢ãƒ‡ãƒ«æ¨å®šå™¨
        self.estimator = None
        
        # è¨“ç·´å±¥æ­´
        self.history = None
        self.training_time = 0
        self.best_val_acc = 0
        
        print("=" * 70)
        print("ğŸ“ ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–")
        print("=" * 70)
        print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
        print(f"ğŸ·ï¸  ãƒ¢ãƒ‡ãƒ«å: {self.model_name}")
    
    def load_data(self, data_dir: str) -> bool:
        """
        ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        
        Args:
            data_dir (str): ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            bool: æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        print("\n" + "=" * 70)
        print("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿")
        print("=" * 70)
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ä½œæˆ
            self.data_manager = DrowsinessDataManager(data_dir=data_dir)
            
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨
            dataset_file = os.path.join(data_dir, 'drowsiness_dataset.npz')
            if os.path.exists(dataset_file):
                print(f"ğŸ“¦ æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿: {dataset_file}")
                self.data_manager.load_dataset(dataset_file)
                return True
            
            # ãªã‘ã‚Œã°ç”Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰èª­ã¿è¾¼ã¿
            print("ğŸ“Š ç”Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰èª­ã¿è¾¼ã¿...")
            success = self.data_manager.load_all_data(verbose=True)
            
            if not success:
                print("âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—")
                return False
            
            # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
            print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å‰²...")
            self.data_manager.split_data(
                train_ratio=self.config.get('train_ratio', 0.7),
                val_ratio=self.config.get('val_ratio', 0.15),
                test_ratio=self.config.get('test_ratio', 0.15),
                stratify=True,
                verbose=True
            )
            
            # æ­£è¦åŒ–
            print("\nğŸ”§ ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–...")
            self.data_manager.normalize_data(
                method=self.config.get('normalization', 'zscore'),
                verbose=True
            )
            
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¿å­˜
            self.data_manager.export_dataset(dataset_file)
            
            # æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¿å­˜
            norm_params_file = os.path.join(data_dir, 'normalization_params.json')
            self.data_manager.save_normalization_params(norm_params_file)
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def create_model(self):
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
        """
        print("\n" + "=" * 70)
        print("ğŸ§  ãƒ¢ãƒ‡ãƒ«ä½œæˆ")
        print("=" * 70)
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        model_params = {
            'input_size': self.config.get('input_size', 6),
            'hidden_size1': self.config.get('hidden_size1', 64),
            'hidden_size2': self.config.get('hidden_size2', 32),
            'fc_size': self.config.get('fc_size', 32),
            'num_classes': self.config.get('num_classes', 2),
            'dropout_rate': self.config.get('dropout_rate', 0.3)
        }
        
        # æ¨å®šå™¨ä½œæˆ
        self.estimator = DrowsinessEstimator(
            model_params=model_params,
            device=self.config.get('device', None)
        )
        
        self.estimator.get_model_summary()
    
    def train_model(self):
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
        """
        if self.data_manager is None:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        if self.estimator is None:
            print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        print("\n" + "=" * 70)
        print("ğŸš€ ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹")
        print("=" * 70)
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿å–å¾—
        train_sequences, train_labels = self.data_manager.get_train_data()
        val_sequences, val_labels = self.data_manager.get_val_data()
        
        # è¨“ç·´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        epochs = self.config.get('epochs', 100)
        batch_size = self.config.get('batch_size', 32)
        learning_rate = self.config.get('learning_rate', 0.001)
        patience = self.config.get('patience', 10)
        
        # è¨“ç·´å®Ÿè¡Œ
        start_time = time.time()
        
        self.history = self.estimator.train_model(
            train_sequences, train_labels,
            val_sequences, val_labels,
            epochs=epochs,
            batch_size=batch_size,
            learning_rate=learning_rate,
            patience=patience,
            verbose=True
        )
        
        self.training_time = time.time() - start_time
        
        # ãƒ™ã‚¹ãƒˆæ¤œè¨¼ç²¾åº¦ã‚’è¨˜éŒ²
        if len(self.history['val_acc']) > 0:
            self.best_val_acc = max(self.history['val_acc'])
        
        print(f"\nâ±ï¸  è¨“ç·´æ™‚é–“: {self.training_time:.1f}ç§’")
        print(f"ğŸ¯ ãƒ™ã‚¹ãƒˆæ¤œè¨¼ç²¾åº¦: {self.best_val_acc:.2f}%")
        
        return True
    
    def evaluate_model(self):
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
        """
        if self.estimator is None:
            print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
        
        print("\n" + "=" * 70)
        print("ğŸ“Š ãƒ¢ãƒ‡ãƒ«è©•ä¾¡")
        print("=" * 70)
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
        test_sequences, test_labels = self.data_manager.get_test_data()
        
        # è©•ä¾¡å®Ÿè¡Œ
        results = self.estimator.evaluate(test_sequences, test_labels)
        
        # è©³ç´°ãªåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ
        print("\nğŸ“ˆ è©³ç´°ãªåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:")
        report = results['classification_report']
        
        for class_name in ['æ­£å¸¸', 'çœ æ°—']:
            if class_name in report:
                metrics = report[class_name]
                print(f"\n{class_name}:")
                print(f"  é©åˆç‡ (Precision): {metrics['precision']:.3f}")
                print(f"  å†ç¾ç‡ (Recall):    {metrics['recall']:.3f}")
                print(f"  F1ã‚¹ã‚³ã‚¢:          {metrics['f1-score']:.3f}")
                print(f"  ã‚µãƒãƒ¼ãƒˆ:          {metrics['support']}")
        
        # ãƒã‚¯ãƒ­å¹³å‡
        if 'macro avg' in report:
            macro = report['macro avg']
            print(f"\nãƒã‚¯ãƒ­å¹³å‡:")
            print(f"  é©åˆç‡: {macro['precision']:.3f}")
            print(f"  å†ç¾ç‡: {macro['recall']:.3f}")
            print(f"  F1ã‚¹ã‚³ã‚¢: {macro['f1-score']:.3f}")
        
        return results
    
    def save_model(self, results: Optional[Dict] = None):
        """
        ãƒ¢ãƒ‡ãƒ«ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        
        Args:
            results (Dict): è©•ä¾¡çµæœ
        """
        print("\n" + "=" * 70)
        print("ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜")
        print("=" * 70)
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        model_path = os.path.join(self.output_dir, f"{self.model_name}.pth")
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        self.estimator.save_model(model_path, include_history=True)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        metadata = {
            'model_name': self.model_name,
            'timestamp': self.timestamp,
            'training_time': self.training_time,
            'best_val_acc': self.best_val_acc,
            'config': self.config,
            'data_statistics': self.data_manager.get_statistics()
        }
        
        if results is not None:
            metadata['test_accuracy'] = results['accuracy']
            metadata['confusion_matrix'] = results['confusion_matrix']
            metadata['classification_report'] = results['classification_report']
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        metadata_path = os.path.join(self.output_dir, f"{self.model_name}_metadata.json")
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2, default=str)
        
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {model_path}")
        print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {metadata_path}")
    
    def plot_training_history(self):
        """
        è¨“ç·´å±¥æ­´ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
        """
        if self.history is None:
            print("âš ï¸ è¨“ç·´å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        print("\n" + "=" * 70)
        print("ğŸ“Š è¨“ç·´å±¥æ­´ã®å¯è¦–åŒ–")
        print("=" * 70)
        
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        
        # æå¤±ã®ãƒ—ãƒ­ãƒƒãƒˆ
        epochs_range = range(1, len(self.history['train_loss']) + 1)
        
        axes[0].plot(epochs_range, self.history['train_loss'], 'b-', label='è¨“ç·´æå¤±', linewidth=2)
        if len(self.history['val_loss']) > 0:
            axes[0].plot(epochs_range, self.history['val_loss'], 'r-', label='æ¤œè¨¼æå¤±', linewidth=2)
        axes[0].set_xlabel('ã‚¨ãƒãƒƒã‚¯', fontsize=12)
        axes[0].set_ylabel('æå¤±', fontsize=12)
        axes[0].set_title('è¨“ç·´æå¤±ã¨æ¤œè¨¼æå¤±', fontsize=14, fontweight='bold')
        axes[0].legend(fontsize=10)
        axes[0].grid(True, alpha=0.3)
        
        # ç²¾åº¦ã®ãƒ—ãƒ­ãƒƒãƒˆ
        axes[1].plot(epochs_range, self.history['train_acc'], 'b-', label='è¨“ç·´ç²¾åº¦', linewidth=2)
        if len(self.history['val_acc']) > 0:
            axes[1].plot(epochs_range, self.history['val_acc'], 'r-', label='æ¤œè¨¼ç²¾åº¦', linewidth=2)
        axes[1].set_xlabel('ã‚¨ãƒãƒƒã‚¯', fontsize=12)
        axes[1].set_ylabel('ç²¾åº¦ (%)', fontsize=12)
        axes[1].set_title('è¨“ç·´ç²¾åº¦ã¨æ¤œè¨¼ç²¾åº¦', fontsize=14, fontweight='bold')
        axes[1].legend(fontsize=10)
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜
        plot_path = os.path.join(self.log_dir, f"{self.model_name}_history.png")
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        print(f"âœ… è¨“ç·´å±¥æ­´ã‚°ãƒ©ãƒ•ä¿å­˜: {plot_path}")
        
        # è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if self.config.get('show_plots', False):
            plt.show()
        else:
            plt.close()
    
    def plot_confusion_matrix(self, results: Dict):
        """
        æ··åŒè¡Œåˆ—ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
        
        Args:
            results (Dict): è©•ä¾¡çµæœ
        """
        import matplotlib.pyplot as plt
        from sklearn.metrics import ConfusionMatrixDisplay
        
        print("\nğŸ“Š æ··åŒè¡Œåˆ—ã®å¯è¦–åŒ–")
        
        cm = np.array(results['confusion_matrix'])
        
        fig, ax = plt.subplots(figsize=(8, 6))
        disp = ConfusionMatrixDisplay(
            confusion_matrix=cm,
            display_labels=['æ­£å¸¸', 'çœ æ°—']
        )
        disp.plot(ax=ax, cmap='Blues', values_format='d')
        ax.set_title('æ··åŒè¡Œåˆ—', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        
        # ä¿å­˜
        cm_path = os.path.join(self.log_dir, f"{self.model_name}_confusion_matrix.png")
        plt.savefig(cm_path, dpi=150, bbox_inches='tight')
        print(f"âœ… æ··åŒè¡Œåˆ—ã‚°ãƒ©ãƒ•ä¿å­˜: {cm_path}")
        
        if self.config.get('show_plots', False):
            plt.show()
        else:
            plt.close()
    
    def run_full_training_pipeline(self, data_dir: str):
        """
        å®Œå…¨ãªè¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ
        
        Args:
            data_dir (str): ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            bool: æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        print("\n" + "=" * 70)
        print("ğŸ“ å®Œå…¨è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹")
        print("=" * 70)
        
        # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        if not self.load_data(data_dir):
            return False
        
        # 2. ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        self.create_model()
        
        # 3. ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        if not self.train_model():
            return False
        
        # 4. è¨“ç·´å±¥æ­´å¯è¦–åŒ–
        self.plot_training_history()
        
        # 5. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
        results = self.evaluate_model()
        
        # 6. æ··åŒè¡Œåˆ—å¯è¦–åŒ–
        if results is not None:
            self.plot_confusion_matrix(results)
        
        # 7. ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        self.save_model(results)
        
        print("\n" + "=" * 70)
        print("âœ… è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†")
        print("=" * 70)
        print(f"ğŸ¯ æœ€çµ‚ãƒ†ã‚¹ãƒˆç²¾åº¦: {results['accuracy']:.2f}%")
        print(f"ğŸ“ ãƒ¢ãƒ‡ãƒ«: {self.output_dir}/{self.model_name}.pth")
        print("=" * 70)
        
        return True


def create_default_config() -> Dict:
    """
    ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½œæˆ
    
    Returns:
        Dict: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
    """
    return {
        # ãƒ‡ãƒ¼ã‚¿è¨­å®š
        'train_ratio': 0.7,
        'val_ratio': 0.15,
        'test_ratio': 0.15,
        'normalization': 'zscore',
        
        # ãƒ¢ãƒ‡ãƒ«è¨­å®š
        'input_size': 6,
        'hidden_size1': 64,
        'hidden_size2': 32,
        'fc_size': 32,
        'num_classes': 2,
        'dropout_rate': 0.3,
        
        # è¨“ç·´è¨­å®š
        'epochs': 100,
        'batch_size': 32,
        'learning_rate': 0.001,
        'patience': 10,
        
        # å‡ºåŠ›è¨­å®š
        'output_dir': 'trained_models',
        'show_plots': False,
        'device': None  # None=è‡ªå‹•é¸æŠ, 'cuda', 'cpu'
    }


def parse_args():
    """
    ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’ãƒ‘ãƒ¼ã‚¹
    
    Returns:
        argparse.Namespace: ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸå¼•æ•°
    """
    parser = argparse.ArgumentParser(
        description='çœ æ°—æ¨å®šLSTMãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    # ãƒ‡ãƒ¼ã‚¿è¨­å®š
    parser.add_argument('--data-dir', type=str, default='drowsiness_training_data',
                       help='ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--output-dir', type=str, default='trained_models',
                       help='ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    
    # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    parser.add_argument('--hidden-size1', type=int, default=64,
                       help='LSTMç¬¬1å±¤ã®ãƒ¦ãƒ‹ãƒƒãƒˆæ•°')
    parser.add_argument('--hidden-size2', type=int, default=32,
                       help='LSTMç¬¬2å±¤ã®ãƒ¦ãƒ‹ãƒƒãƒˆæ•°')
    parser.add_argument('--fc-size', type=int, default=32,
                       help='å…¨çµåˆå±¤ã®ãƒ¦ãƒ‹ãƒƒãƒˆæ•°')
    parser.add_argument('--dropout', type=float, default=0.3,
                       help='ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡')
    
    # è¨“ç·´è¨­å®š
    parser.add_argument('--epochs', type=int, default=100,
                       help='ã‚¨ãƒãƒƒã‚¯æ•°')
    parser.add_argument('--batch-size', type=int, default=32,
                       help='ãƒãƒƒãƒã‚µã‚¤ã‚º')
    parser.add_argument('--lr', type=float, default=0.001,
                       help='å­¦ç¿’ç‡')
    parser.add_argument('--patience', type=int, default=10,
                       help='Early Stoppingã®å¿è€å€¤')
    
    # ãã®ä»–
    parser.add_argument('--device', type=str, default=None,
                       choices=['cuda', 'cpu', None],
                       help='ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹')
    parser.add_argument('--show-plots', action='store_true',
                       help='ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹')
    parser.add_argument('--config', type=str, default=None,
                       help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆJSONï¼‰')
    
    return parser.parse_args()


def load_config_from_file(filepath: str) -> Dict:
    """
    è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    
    Args:
        filepath (str): è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
    Returns:
        Dict: è¨­å®š
    """
    try:
        with open(filepath, 'r') as f:
            config = json.load(f)
        print(f"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {filepath}")
        return config
    except Exception as e:
        print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return {}


def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    print("=" * 70)
    print("ğŸ“ çœ æ°—æ¨å®šãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 70)
    
    # å¼•æ•°ãƒ‘ãƒ¼ã‚¹
    args = parse_args()
    
    # è¨­å®šä½œæˆ
    if args.config is not None:
        config = load_config_from_file(args.config)
    else:
        config = create_default_config()
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ä¸Šæ›¸ã
    config['output_dir'] = args.output_dir
    config['hidden_size1'] = args.hidden_size1
    config['hidden_size2'] = args.hidden_size2
    config['fc_size'] = args.fc_size
    config['dropout_rate'] = args.dropout
    config['epochs'] = args.epochs
    config['batch_size'] = args.batch_size
    config['learning_rate'] = args.lr
    config['patience'] = args.patience
    config['device'] = args.device
    config['show_plots'] = args.show_plots
    
    # è¨­å®šè¡¨ç¤º
    print("\nğŸ“‹ è¨“ç·´è¨­å®š:")
    print(json.dumps(config, indent=2))
    
    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ä½œæˆ
    trainer = ModelTrainer(config)
    
    # è¨“ç·´å®Ÿè¡Œ
    success = trainer.run_full_training_pipeline(args.data_dir)
    
    if success:
        print("\nğŸ‰ è¨“ç·´ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        sys.exit(0)
    else:
        print("\nâŒ è¨“ç·´ã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)


if __name__ == "__main__":
    main()
