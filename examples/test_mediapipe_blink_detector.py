"""
MediaPipeç‰ˆç¬ãæ¤œå‡ºå™¨ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ã„æ–¹:
    python test_mediapipe_blink_detector.py

æ©Ÿèƒ½:
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§é¡”ã¨ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æ¤œå‡º
- EARå€¤ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
- ç¬ãæ¤œå‡ºã¨ã‚«ã‚¦ãƒ³ãƒˆ
- ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½
"""

import cv2
import numpy as np
import time
from blink_detector_mediapipe import BlinkDetectorMediaPipe


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("=" * 60)
    print("MediaPipeç‰ˆç¬ãæ¤œå‡ºå™¨ - ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ")
    print("=" * 60)
    print()
    print("æ“ä½œæ–¹æ³•:")
    print("  [C] - ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹ï¼ˆ5ç§’é–“ï¼‰")
    print("  [R] - çµ±è¨ˆæƒ…å ±ã‚’ãƒªã‚»ãƒƒãƒˆ")
    print("  [ESC] - çµ‚äº†")
    print()
    print("=" * 60)
    
    # ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        print("âŒ ã‚¨ãƒ©ãƒ¼: ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“")
        return
    
    # ã‚«ãƒ¡ãƒ©è¨­å®š
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap.set(cv2.CAP_PROP_FPS, 30)
    
    print("âœ… ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–å®Œäº†")
    
    # MediaPipeç¬ãæ¤œå‡ºå™¨ã®åˆæœŸåŒ–
    detector = BlinkDetectorMediaPipe(
        buffer_size=300,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    )
    
    print("âœ… MediaPipe Face MeshåˆæœŸåŒ–å®Œäº†")
    print()
    print("æº–å‚™å®Œäº†ï¼[C]ã‚­ãƒ¼ã§ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¦ãã ã•ã„")
    print()
    
    # FPSè¨ˆæ¸¬ç”¨
    fps_start_time = time.time()
    fps_frame_count = 0
    fps = 0
    
    while True:
        ret, frame = cap.read()
        
        if not ret:
            print("âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—å¤±æ•—")
            break
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å·¦å³åè»¢ï¼ˆé¡åƒè¡¨ç¤ºï¼‰
        frame = cv2.flip(frame, 1)
        
        # FPSè¨ˆç®—
        fps_frame_count += 1
        if fps_frame_count >= 30:
            fps_end_time = time.time()
            fps = fps_frame_count / (fps_end_time - fps_start_time)
            fps_start_time = fps_end_time
            fps_frame_count = 0
        
        # é¡”ã¨ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æ¤œå‡º
        landmarks = detector.detect_face_and_landmarks(frame)
        
        # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆ
        if landmarks is not None:
            # EARè¨ˆç®—
            current_ear = detector.calculate_ear_from_landmarks(landmarks, frame.shape)
            
            # ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸­ã®å‡¦ç†
            if detector.calibration_active:
                elapsed = time.time() - detector.calibration_start_time
                remaining = detector.calibration_duration - elapsed
                
                # é€²æ—ãƒãƒ¼
                progress = int((elapsed / detector.calibration_duration) * 100)
                bar_length = 30
                filled = int((progress / 100) * bar_length)
                bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)
                
                # ç”»é¢ã«è¡¨ç¤º
                cv2.putText(frame, f"CALIBRATING: {remaining:.1f}s", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                cv2.putText(frame, f"[{bar}] {progress}%", 
                           (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
            
            # ç¬ãæ¤œå‡º
            blink_info = detector.detect_blink(frame)
            
            # ç¬ããŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆ
            if blink_info is not None:
                print(f"ğŸ‘ï¸ ç¬ãæ¤œå‡º! "
                      f"é–‰çœ¼æ™‚é–“: {blink_info['closing_time']*1000:.1f}ms, "
                      f"é–‹çœ¼æ™‚é–“: {blink_info['opening_time']*1000:.1f}ms, "
                      f"ä¿‚æ•°: {blink_info['blink_coefficient']:.2f}")
            
            # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æç”»ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            frame = detector.draw_landmarks(frame, landmarks)
            
            # çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
            stats = detector.get_statistics()
            
            # æƒ…å ±ã‚’ç”»é¢ã«è¡¨ç¤º
            y_offset = 30
            line_height = 30
            
            # EARå€¤ï¼ˆè‰²åˆ†ã‘ï¼‰
            ear_color = (0, 255, 0)  # ç·‘
            if detector.ear_closed_threshold and current_ear <= detector.ear_closed_threshold:
                ear_color = (0, 0, 255)  # èµ¤ï¼ˆé–‰çœ¼ï¼‰
            elif detector.ear_closing_threshold and current_ear <= detector.ear_closing_threshold:
                ear_color = (0, 165, 255)  # ã‚ªãƒ¬ãƒ³ã‚¸ï¼ˆé–‰çœ¼é€”ä¸­ï¼‰
            
            cv2.putText(frame, f"EAR: {current_ear:.3f}", 
                       (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, ear_color, 2)
            y_offset += line_height
            
            # ç¬ãå›æ•°
            cv2.putText(frame, f"Blinks: {stats['total_blinks']}", 
                       (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            y_offset += line_height
            
            # ç¬ãç‡
            cv2.putText(frame, f"Rate: {stats['current_blink_rate']:.1f}/min", 
                       (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            y_offset += line_height
            
            # å¹³å‡æŒç¶šæ™‚é–“
            cv2.putText(frame, f"Avg Duration: {stats['avg_duration']*1000:.0f}ms", 
                       (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            y_offset += line_height
            
            # ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹
            calib_text = "Calibrated: YES" if stats['calibrated'] else "Calibrated: NO (Press C)"
            calib_color = (0, 255, 0) if stats['calibrated'] else (0, 0, 255)
            cv2.putText(frame, calib_text, 
                       (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, calib_color, 2)
            y_offset += line_height
            
            # ç¬ãçŠ¶æ…‹
            state_names = {
                detector.BLINK_STATE_OPEN: "OPEN",
                detector.BLINK_STATE_CLOSING: "CLOSING",
                detector.BLINK_STATE_CLOSED: "CLOSED",
                detector.BLINK_STATE_OPENING: "OPENING"
            }
            state_text = f"State: {state_names.get(detector.blink_state, 'UNKNOWN')}"
            cv2.putText(frame, state_text, 
                       (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
            
        else:
            # é¡”ãŒæ¤œå‡ºã•ã‚Œãªã„å ´åˆ
            cv2.putText(frame, "No face detected", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        # FPSè¡¨ç¤º
        cv2.putText(frame, f"FPS: {fps:.1f}", 
                   (frame.shape[1] - 120, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
        cv2.imshow("MediaPipe Blink Detector Test", frame)
        
        # ã‚­ãƒ¼å…¥åŠ›å‡¦ç†
        key = cv2.waitKey(1) & 0xFF
        
        if key == 27:  # ESC
            print("\nçµ‚äº†ã—ã¾ã™...")
            break
        elif key == ord('c') or key == ord('C'):
            print("\nğŸ¯ ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")
            detector.start_calibration()
        elif key == ord('r') or key == ord('R'):
            print("\nğŸ”„ çµ±è¨ˆæƒ…å ±ã‚’ãƒªã‚»ãƒƒãƒˆ")
            detector.blink_count = 0
            detector.blink_times.clear()
            detector.blink_durations.clear()
            detector.blink_details.clear()
    
    # çµ‚äº†å‡¦ç†
    cap.release()
    cv2.destroyAllWindows()
    
    # æœ€çµ‚çµ±è¨ˆ
    print("\n" + "=" * 60)
    print("æœ€çµ‚çµ±è¨ˆ")
    print("=" * 60)
    stats = detector.get_statistics()
    print(f"ç·ç¬ãå›æ•°: {stats['total_blinks']}")
    print(f"å¹³å‡ç¬ãç‡: {stats['current_blink_rate']:.1f} å›/åˆ†")
    print(f"å¹³å‡æŒç¶šæ™‚é–“: {stats['avg_duration']*1000:.1f} ms")
    print("=" * 60)


if __name__ == "__main__":
    main()
